# -*- coding: utf-8 -*-
import pandas as pd
import os
import json
import time # API í˜¸ì¶œ ê°„ ì§€ì—°ì„ ìœ„í•´
import openpyxl # .xlsx íŒŒì¼ ì²˜ë¦¬ë¥¼ ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤. (pip install openpyxl)
import xlrd     # .xls íŒŒì¼ ì²˜ë¦¬ë¥¼ ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤. (pip install xlrd >= 2.0.1 ê¶Œì¥)
from zipfile import BadZipFile # íŠ¹ì • ì˜¤ë¥˜ ì²˜ë¦¬ë¥¼ ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤.
import sys

# ì¦‰ì‹œ ì¶œë ¥ìœ¼ë¡œ GUIì—ì„œ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ í™•ì¸
print("[ì‹œì‘] Auto_reconcile_byGemini.py ëª¨ë“ˆ ì§„ì…", flush=True)
print(f"[ì‹œê°„] {pd.Timestamp.now().strftime('%H:%M:%S')}", flush=True)
print(f"[ì¸ìˆ˜] sys.argv: {sys.argv}", flush=True)
print(f"[ê²½ë¡œ] í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}", flush=True)

# Google Gemini API ì—°ë™ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ (pip install google-generativeai)
import google.generativeai as genai
import requests
from datetime import datetime, timedelta

# Config íŒŒì¼ì—ì„œ ì¸ì½”í…€ì¦ˆ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
try:
    from Config.config import AI_RECONCILIATION_CONFIG
    INCOTERMS_CONFIG = AI_RECONCILIATION_CONFIG.get("incoterms_revenue_recognition", {})
except ImportError:
    # Config íŒŒì¼ì´ ì—†ì„ ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
    INCOTERMS_CONFIG = {
        "CFR": {"revenue_date": "shipment_date", "description": "ì„ ì ì¼ ê¸°ì¤€"},
        "CIF": {"revenue_date": "shipment_date", "description": "ì„ ì ì¼ ê¸°ì¤€"},
        "FOB": {"revenue_date": "shipment_date", "description": "ì„ ì ì¼ ê¸°ì¤€"},
        "EXW": {"revenue_date": "factory_release_date", "description": "ê³µì¥ì¶œê³ ì¼ ê¸°ì¤€"},
        "DAP": {"revenue_date": "arrival_date", "description": "ë„ì°©ì¼ ê¸°ì¤€"},
        "DDP": {"revenue_date": "arrival_date", "description": "ë„ì°©ì¼ ê¸°ì¤€"}
    }

# --- ì„¤ì •ê°’ ---
# ê¸°ë³¸ê°’ë“¤ì€ Noneìœ¼ë¡œ ì„¤ì •í•˜ì—¬ GUIì—ì„œ ì „ë‹¬ë°›ì€ ê²½ë¡œë¥¼ ìš°ì„  ì‚¬ìš©
DEFAULT_INPUT_EXCEL_PATH = None
DEFAULT_OUTPUT_DIR = None
DEFAULT_OCR_JSON_DIR = None

# ì²´í¬í¬ì¸íŠ¸ ì„¤ì •
CHECKPOINT_INTERVAL = 20  # 20ê±´ë§ˆë‹¤ ì²´í¬í¬ì¸íŠ¸ ì €ì¥

# AI ëŒ€ì‚¬ ê²°ê³¼ ì»¬ëŸ¼ ì •ì˜
RECONCILIATION_COLUMNS = [
    "amount_match",      # ê¸ˆì•¡ ëŒ€ì‚¬
    "quantity_match",    # ìˆ˜ëŸ‰ ëŒ€ì‚¬
    "date_match",        # ë§¤ì¶œì¼ì ëŒ€ì‚¬
    "customer_match",    # ê³ ê°/êµ¬ë§¤ì²˜ ëŒ€ì‚¬
    "overall_status",    # ì „ì²´ ìƒíƒœ (ì˜ì–´)
    "ì „ì²´ê²°ê³¼",          # ì „ì²´ ìƒíƒœ (í•œê¸€)
    "notes"             # ë¹„ê³  (íŠ¹ì´ì‚¬í•­)
]

# ì¦ë¹™ì—ì„œ ì½ì–´ì˜¨ ì‹¤ì œ ê°’ë“¤ì„ í‘œì‹œí•  ì»¬ëŸ¼ë“¤
EVIDENCE_VALUE_COLUMNS = [
    "evidence_amount",   # ì¦ë¹™ì—ì„œ ì½ì–´ì˜¨ ê¸ˆì•¡
    "evidence_quantity", # ì¦ë¹™ì—ì„œ ì½ì–´ì˜¨ ìˆ˜ëŸ‰
    "evidence_date",     # ì¦ë¹™ì—ì„œ ì½ì–´ì˜¨ ë‚ ì§œ
    "evidence_customer"  # ì¦ë¹™ì—ì„œ ì½ì–´ì˜¨ ê³ ê°ì‚¬
]

# --- Gemini API ì„¤ì • ---
# !!! ì¤‘ìš”: ì—¬ê¸°ì— ì‚¬ìš©ìë‹˜ì˜ ì‹¤ì œ Gemini API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš” !!!
GEMINI_API_KEY = "your_api_key" # <--- ì‚¬ìš©ìë‹˜ì˜ ì •í™•í•œ API í‚¤

def initialize_gemini_api():
    """Gemini API ì´ˆê¸°í™”"""
    print(f"ğŸ” Gemini API ì´ˆê¸°í™” ì‹œì‘: {datetime.now().strftime('%H:%M:%S')}", flush=True)
    
    # API í‚¤ ìœ íš¨ì„± ì´ˆê¸° í™•ì¸
    if GEMINI_API_KEY == "YOUR_GEMINI_API_KEY" or not GEMINI_API_KEY.strip() or len(GEMINI_API_KEY) < 39:
        print("âŒ ì˜¤ë¥˜: Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šì€ í˜•ì‹ì…ë‹ˆë‹¤. 'GEMINI_API_KEY' ë³€ìˆ˜ì— ì‹¤ì œ í‚¤ë¥¼ ì •í™•íˆ ì…ë ¥í•´ì£¼ì„¸ìš”.", flush=True)
        return None

    try:
        print(f"ğŸ” API í‚¤ ì„¤ì • ì¤‘... (í‚¤ ê¸¸ì´: {len(GEMINI_API_KEY)})", flush=True)
        genai.configure(api_key=GEMINI_API_KEY)
        print(f"ğŸ” API í‚¤ ì„¤ì • ì™„ë£Œ: {datetime.now().strftime('%H:%M:%S')}", flush=True)
        
        # ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ê±´ë„ˆë›°ê³  ì§ì ‘ ëª¨ë¸ ì‹œë„
        print(f"ğŸ” ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ê±´ë„ˆë›°ê³  ì§ì ‘ ëª¨ë¸ ì‹œë„: {datetime.now().strftime('%H:%M:%S')}", flush=True)
        
        # ëª¨ë¸ ì„ íƒ ë¡œì§ ë‹¨ìˆœí™”
        GEMINI_MODEL_NAME = 'gemini-1.5-flash'  # ê¸°ë³¸ ëª¨ë¸ë¡œ ì„¤ì •
        
        try:
            gemini_model = genai.GenerativeModel(GEMINI_MODEL_NAME)
            
            # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ìš”ì²­ìœ¼ë¡œ API í‚¤ ìœ íš¨ì„± í™•ì¸
            print(f"ğŸ” API í‚¤ ìœ íš¨ì„± í…ŒìŠ¤íŠ¸ ì¤‘...", flush=True)
            test_response = gemini_model.generate_content("Hello")
            if test_response and test_response.text:
                print(f"âœ… Gemini API ì„¤ì • ë° ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ. ì‚¬ìš© ëª¨ë¸: {GEMINI_MODEL_NAME}", flush=True)
                return gemini_model
            else:
                print(f"âš ï¸ API í…ŒìŠ¤íŠ¸ ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.", flush=True)
                return None
                
        except Exception as e:
            print(f"âš ï¸ ê¸°ë³¸ ëª¨ë¸ '{GEMINI_MODEL_NAME}' ë¡œë“œ ì‹¤íŒ¨: {e}", flush=True)
            
            # ëŒ€ì²´ ëª¨ë¸ ì‹œë„
            fallback_models = ['gemini-1.5-pro', 'gemini-1.0-pro', 'gemini-pro']
            for fallback_model in fallback_models:
                try:
                    print(f"ğŸ” ëŒ€ì²´ ëª¨ë¸ ì‹œë„: {fallback_model}", flush=True)
                    gemini_model = genai.GenerativeModel(fallback_model)
                    
                    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ìš”ì²­
                    test_response = gemini_model.generate_content("Hello")
                    if test_response and test_response.text:
                        print(f"âœ… ëŒ€ì²´ ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {fallback_model}", flush=True)
                        return gemini_model
                    else:
                        print(f"âš ï¸ ëŒ€ì²´ ëª¨ë¸ '{fallback_model}' í…ŒìŠ¤íŠ¸ ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.", flush=True)
                        continue
                        
                except Exception as fallback_error:
                    print(f"âŒ ëŒ€ì²´ ëª¨ë¸ '{fallback_model}' ì‹¤íŒ¨: {fallback_error}", flush=True)
                    continue
            
            print("âŒ ëª¨ë“  ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨. API í‚¤ë‚˜ ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.", flush=True)
            return None
        
    except Exception as e:
        print(f"âŒ Gemini API ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", flush=True)
        print("API í‚¤ê°€ ìœ íš¨í•œì§€, Google Cloud í”„ë¡œì íŠ¸ì—ì„œ Generative Language APIê°€ í™œì„±í™”ë˜ì–´ ìˆê³  ê²°ì œ ê³„ì •ì´ ì—°ê²°ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš” (`pip install google-generativeai`).", flush=True)
        return None

def get_gemini_usage_info():
    """Gemini API ì›”ë³„ ì‚¬ìš©ëŸ‰ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    try:
        # Google AI Studio APIë¥¼ í†µí•œ ì‚¬ìš©ëŸ‰ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        # ì°¸ê³ : ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Google Cloud Billing APIë‚˜ ë‹¤ë¥¸ ë°©ë²•ì„ ì‚¬ìš©í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
        url = "https://generativelanguage.googleapis.com/v1beta/models"
        headers = {
            "x-goog-api-key": GEMINI_API_KEY,
            "Content-Type": "application/json"
        }
        
        response = requests.get(url, headers=headers)
        if response.status_code == 200:
            # ì‹¤ì œ ì‚¬ìš©ëŸ‰ ì •ë³´ëŠ” ë³„ë„ API ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ê°€ì ¸ì™€ì•¼ í•©ë‹ˆë‹¤
            # í˜„ì¬ëŠ” ëª¨ì˜ ë°ì´í„°ë¥¼ ë°˜í™˜
            current_month = datetime.now().strftime("%Y-%m")
            return {
                "current_month": current_month,
                "total_input_tokens": 0,  # ì‹¤ì œ APIì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨
                "total_output_tokens": 0,  # ì‹¤ì œ APIì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨
                "quota_limit": 15000000,  # Gemini Pro ë¬´ë£Œ í• ë‹¹ëŸ‰ (ì›” 15M í† í°)
                "quota_remaining": 15000000  # ì‹¤ì œ APIì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨
            }
        else:
            print(f"âš ï¸ ì‚¬ìš©ëŸ‰ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {response.status_code}", flush=True)
            return None
            
    except Exception as e:
        print(f"âš ï¸ ì‚¬ìš©ëŸ‰ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}", flush=True)
        return None

# --- ì—‘ì…€ íŒŒì¼ ë¡œë”© í•¨ìˆ˜ (ê²¬ê³ í•˜ê²Œ) ---
def load_excel_robustly(file_path, sheet_name=None):
    """
    ì—‘ì…€ íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ê²¬ê³ í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.
    .xlsx íŒŒì¼ì„ openpyxlë¡œ ë¨¼ì € ì‹œë„í•˜ê³ , ì‹¤íŒ¨ ì‹œ xlrdë¡œ .xls íŒŒì¼ì²˜ëŸ¼ ì‹œë„í•©ë‹ˆë‹¤.
    """
    print(f"â–¶ï¸ ì—‘ì…€ íŒŒì¼ ë¡œë”© ì‹œë„: {file_path}", flush=True)

    try:
        if sheet_name:
            df = pd.read_excel(file_path, engine='openpyxl', sheet_name=sheet_name)
        else:
            df = pd.read_excel(file_path, engine='openpyxl')
        print(f"âœ… 'openpyxl' ì—”ì§„ìœ¼ë¡œ ì—‘ì…€ íŒŒì¼ ë¡œë”© ì„±ê³µ!", flush=True)
        return df
    except (BadZipFile, KeyError, FileNotFoundError, ValueError) as e:
        print(f" - 'openpyxl' ì‹œë„ ì‹¤íŒ¨ (ì˜¤ë¥˜ ìœ í˜•: {type(e).__name__}): {e}", flush=True)
    except Exception as e:
        print(f" - 'openpyxl' ì‹œë„ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}", flush=True)

    try:
        if sheet_name:
            df = pd.read_excel(file_path, engine='xlrd', sheet_name=sheet_name)
        else:
            df = pd.read_excel(file_path, engine='xlrd')
        print(f"âœ… 'xlrd' ì—”ì§„ìœ¼ë¡œ ì—‘ì…€ íŒŒì¼ ë¡œë”© ì„±ê³µ!", flush=True)
        return df
    except ImportError:
        print(" - 'xlrd' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë²„ì „ì´ ë‚®ìŠµë‹ˆë‹¤. 'pip install xlrd'ë¥¼ ì‹¤í–‰í•´ ì£¼ì„¸ìš”.", flush=True)
    except Exception as e:
        print(f" - 'xlrd' ì‹œë„ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}", flush=True)

    print(f"âŒ ì—‘ì…€ íŒŒì¼ ë¡œë”© ìµœì¢… ì‹¤íŒ¨: {file_path}", flush=True)
    print("ğŸ’¡ **í•´ê²° íŒ:**", flush=True)
    print("   1. í•´ë‹¹ ì—‘ì…€ íŒŒì¼ì„ Microsoft Excelì—ì„œ ì§ì ‘ ì—´ì–´ 'ë‹¤ë¥¸ ì´ë¦„ìœ¼ë¡œ ì €ì¥'ì„ í†µí•´ **'Excel í†µí•© ë¬¸ì„œ(*.xlsx)'** ë˜ëŠ” **'Excel 97-2003 í†µí•© ë¬¸ì„œ(*.xls)'** í˜•ì‹ìœ¼ë¡œ **ìƒˆ íŒŒì¼ë¡œ ë‹¤ì‹œ ì €ì¥**í•œ í›„, í•´ë‹¹ ìƒˆ íŒŒì¼ë¡œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹œë„í•´ ë³´ì„¸ìš”.", flush=True)
    print("   2. `pandas`, `openpyxl`, `xlrd` ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ëª¨ë‘ ìµœì‹  ë²„ì „ì¸ì§€ í™•ì¸í•´ ë³´ì„¸ìš” (`pip install --upgrade pandas openpyxl xlrd`).", flush=True)
    return None

def save_checkpoint(df_results, output_dir, completed_count, total_count, timestamp):
    """ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        checkpoint_file = os.path.join(output_dir, f"checkpoint_Gemini_{timestamp}.json")
        checkpoint_data = {
            "timestamp": timestamp,
            "completed_count": completed_count,
            "total_count": total_count,
            "completed_docs": df_results[df_results['ì „ì²´ê²°ê³¼'].notna()]['Doc_No'].tolist(),
            "last_updated": datetime.now().isoformat()
        }
        
        with open(checkpoint_file, 'w', encoding='utf-8') as f:
            json.dump(checkpoint_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì™„ë£Œ: {checkpoint_file}", flush=True)
        return checkpoint_file
    except Exception as e:
        print(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}", flush=True)
        return None

def load_checkpoint(output_dir, timestamp):
    """ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        checkpoint_file = os.path.join(output_dir, f"checkpoint_Gemini_{timestamp}.json")
        if os.path.exists(checkpoint_file):
            with open(checkpoint_file, 'r', encoding='utf-8') as f:
                checkpoint_data = json.load(f)
            print(f"ğŸ“‚ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì™„ë£Œ: {checkpoint_file}", flush=True)
            return checkpoint_data
        else:
            print(f"ğŸ“‚ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {checkpoint_file}", flush=True)
            return None
    except Exception as e:
        print(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}", flush=True)
        return None

def save_intermediate_results(df_results, output_dir, timestamp, suffix=""):
    """ì¤‘ê°„ ê²°ê³¼ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        if suffix:
            filename = f"ë§¤ì¶œì¦ë¹™ëŒ€ì‚¬ê²°ê³¼_Gemini_{timestamp}_{suffix}.xlsx"
        else:
            filename = f"ë§¤ì¶œì¦ë¹™ëŒ€ì‚¬ê²°ê³¼_Gemini_{timestamp}_ì§„í–‰ì¤‘.xlsx"
        
        output_path = os.path.join(output_dir, filename)
        
        # ì™„ë£Œëœ ê²°ê³¼ë§Œ í•„í„°ë§í•˜ì—¬ ì €ì¥
        completed_results = df_results[df_results['ì „ì²´ê²°ê³¼'].notna()].copy()
        
        if not completed_results.empty:
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                completed_results.to_excel(writer, sheet_name='AI_ëŒ€ì‚¬ê²°ê³¼', index=False)
            
            print(f"ğŸ’¾ ì¤‘ê°„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path} ({len(completed_results)}ê±´)", flush=True)
            return output_path
        else:
            print(f"âš ï¸ ì €ì¥í•  ì™„ë£Œëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.", flush=True)
            return None
    except Exception as e:
        print(f"âš ï¸ ì¤‘ê°„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}", flush=True)
        return None

def find_original_pdf_files(doc_no, original_pdf_dir):
    """ì „í‘œë²ˆí˜¸ì— í•´ë‹¹í•˜ëŠ” ì›ë³¸ PDF íŒŒì¼ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤."""
    pdf_files = []
    try:
        for filename in os.listdir(original_pdf_dir):
            if filename.lower().endswith('.pdf'):
                # ì „í‘œë²ˆí˜¸_ë¬¸ì„œëª… í˜•ì‹ìœ¼ë¡œ ì €ì¥ëœ íŒŒì¼ë“¤ì—ì„œ í•´ë‹¹ ì „í‘œë²ˆí˜¸ ì°¾ê¸°
                if filename.startswith(f"{doc_no}_") or filename.startswith(doc_no):
                    pdf_files.append(os.path.join(original_pdf_dir, filename))
    except Exception as e:
        print(f"âš ï¸ ì¦ë¹™ì›ë³¸ í´ë” ìŠ¤ìº” ì¤‘ ì˜¤ë¥˜: {e}", flush=True)
    
    return pdf_files

def reconcile_with_pdf_original(erp_info, pdf_files, gemini_model):
    """PDF ì›ë³¸ì„ ì‚¬ìš©í•˜ì—¬ ëŒ€ì‚¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    if not pdf_files:
        return {"overall_status": "NO_EVIDENCE", "notes": "PDF ì›ë³¸ íŒŒì¼ ì—†ìŒ"}
    
    try:
        # PDF íŒŒì¼ë“¤ì„ Geminiì— ì—…ë¡œë“œ
        uploaded_files = []
        for pdf_path in pdf_files:
            try:
                uploaded_file = genai.upload_file(pdf_path)
                uploaded_files.append(uploaded_file)
                print(f"âœ… PDF ì—…ë¡œë“œ ì™„ë£Œ: {os.path.basename(pdf_path)}", flush=True)
            except Exception as e:
                print(f"âš ï¸ PDF ì—…ë¡œë“œ ì‹¤íŒ¨: {os.path.basename(pdf_path)} - {e}", flush=True)
        
        if not uploaded_files:
            return {"overall_status": "NEEDS_REVIEW", "notes": "PDF íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨"}
        
        # ERP ë°ì´í„° ì§ë ¬í™” ì²˜ë¦¬
        serializable_erp_info = {}
        for key, value in erp_info.items():
            try:
                if pd.isna(value) or value is pd.NaT:
                    serializable_erp_info[key] = ""
                elif isinstance(value, pd.Timestamp):
                    serializable_erp_info[key] = value.isoformat()
                else:
                    serializable_erp_info[key] = value
            except Exception as e:
                serializable_erp_info[key] = str(value) if value is not None else ""
        
        # PDF ëŒ€ì‚¬ìš© í”„ë¡¬í”„íŠ¸ (ë‚ ì§œ ë§¤ì¹­ ë¡œì§ ê°œì„ )
        pdf_prompt = f"""
        ì´ PDF ì¦ë¹™ ë¬¸ì„œë“¤ì„ ë¶„ì„í•˜ì—¬ ERP ë°ì´í„°ì™€ ëŒ€ì‚¬í•´ì£¼ì„¸ìš”.
        
        **ERP ë°ì´í„°:**
        {json.dumps(serializable_erp_info, indent=2, ensure_ascii=False)}
        
        **ë‚ ì§œ ë§¤ì¹­ ìš°ì„ ìˆœìœ„ (ë§¤ì¶œì¼ì ê¸°ì¤€):**
        1. **ë§¤ì¶œì¼ì (P_Date)**: ERPì˜ ë§¤ì¶œì¼ìì™€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ë‚ ì§œë¥¼ ìš°ì„  ì°¾ê¸°
        2. **ìˆ˜ì¶œì‹ ê³ ì¼**: ìˆ˜ì¶œì‹ ê³ í•„ì¦ì˜ ë‚ ì§œëŠ” ì°¸ê³ ìš©ì´ë¯€ë¡œ, ë§¤ì¶œì¼ìì™€ ë‹¤ë¥´ë©´ ë¬´ì‹œ
        3. **ê¸°íƒ€ ë‚ ì§œ**: ì†¡ì¥ì¼ì, ë°°ì†¡ì¼ì ë“±ì€ ë§¤ì¶œì¼ìì™€ ì¼ì¹˜í•  ë•Œë§Œ ì‚¬ìš©
        4. **ë‚ ì§œ í˜•ì‹**: YYYY-MM-DD, YYYY.MM.DD, YYYY/MM/DD ë“± ë‹¤ì–‘í•œ í˜•ì‹ í™•ì¸
        5. **ì¼ì¹˜ íŒë‹¨**: ERP ë§¤ì¶œì¼ìì™€ ì¦ë¹™ì˜ ë‚ ì§œê°€ ì •í™•íˆ ì¼ì¹˜í•˜ë©´ MATCHED
        6. **ë¶ˆì¼ì¹˜ íŒë‹¨**: ë§¤ì¶œì¼ìì™€ ë‹¤ë¥¸ ë‚ ì§œë§Œ ìˆìœ¼ë©´ MISMATCHED
        
        **ì¸ì½”í…€ì¦ˆë³„ ë§¤ì¶œì¸ì‹ì¼ ê¸°ì¤€:**
        """
        
        # ì¸ì½”í…€ì¦ˆ ì„¤ì •ì„ PDF í”„ë¡¬í”„íŠ¸ì—ë„ ì¶”ê°€
        for incoterm, config in INCOTERMS_CONFIG.items():
            pdf_prompt += f"- {incoterm}: {config['description']}\n"
        
        pdf_prompt += f"""
        
        **ë¶„ì„ ìš”ì²­ì‚¬í•­:**
        1. ê¸ˆì•¡ (Amount) - ERP ê¸ˆì•¡ê³¼ ì¦ë¹™ ê¸ˆì•¡ ë¹„êµ (ì ˆëŒ€ê°’ ì‚¬ìš©)
        2. ìˆ˜ëŸ‰ (Quantity) - ERP ìˆ˜ëŸ‰ê³¼ ì¦ë¹™ ìˆ˜ëŸ‰ ë¹„êµ (ì •í™•íˆ ì¼ì¹˜)
        3. ë‚ ì§œ (Date) - ERP ë§¤ì¶œì¼ìì™€ ì¦ë¹™ ë‚ ì§œ ë¹„êµ (ìœ„ ìš°ì„ ìˆœìœ„ ì ìš©)
        4. ê³ ê°ì‚¬ëª… (Customer) - ERP ê³ ê°ì‚¬ì™€ ì¦ë¹™ ê³ ê°ì‚¬ ë¹„êµ
        
        **ì¤‘ìš” ì‚¬í•­:**
        - ìˆ˜ì¶œì‹ ê³ í•„ì¦ì˜ ë‚ ì§œëŠ” ìˆ˜ì¶œì‹ ê³ ì¼ì´ë¯€ë¡œ ë§¤ì¶œì¼ìì™€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
        - ERP ë§¤ì¶œì¼ìì™€ ì¼ì¹˜í•˜ëŠ” ë‚ ì§œë¥¼ ì°¾ì•„ì•¼ í•¨
        - ì—¬ëŸ¬ ë‚ ì§œê°€ ìˆì„ ë•ŒëŠ” ë§¤ì¶œì¼ìì™€ ì¼ì¹˜í•˜ëŠ” ê²ƒì„ ìš°ì„  ì„ íƒ
        
        **ì‘ë‹µ í˜•ì‹ (JSON):**
        {{
            "amount_match": "MATCHED/MISMATCHED/NEEDS_REVIEW",
            "quantity_match": "MATCHED/MISMATCHED/NEEDS_REVIEW", 
            "date_match": "MATCHED/MISMATCHED/NEEDS_REVIEW",
            "customer_match": "MATCHED/MISMATCHED/NEEDS_REVIEW",
            "overall_status": "MATCHED/MISMATCHED/NEEDS_REVIEW",
            "evidence_amount": "ì¦ë¹™ì—ì„œ ì½ì€ ê¸ˆì•¡",
            "evidence_quantity": "ì¦ë¹™ì—ì„œ ì½ì€ ìˆ˜ëŸ‰",
            "evidence_date": "ì¦ë¹™ì—ì„œ ì½ì€ ë‚ ì§œ",
            "evidence_customer": "ì¦ë¹™ì—ì„œ ì½ì€ ê³ ê°ì‚¬",
            "notes": "ìƒì„¸ ë¶„ì„ ê²°ê³¼ ë° íŠ¹ì´ì‚¬í•­"
        }}
        """
        
        # Gemini API í˜¸ì¶œ (PDF íŒŒì¼ í¬í•¨)
        response = gemini_model.generate_content([pdf_prompt] + uploaded_files)
        
        if not response.text:
            return {"overall_status": "NEEDS_REVIEW", "notes": "PDF ë¶„ì„ ì‘ë‹µ ì—†ìŒ"}
        
        # JSON íŒŒì‹±
        raw_text = response.text.strip()
        raw_text = raw_text.replace('```json', '').replace('```', '').strip()
        
        if raw_text.lower().startswith('json\n'):
            raw_text = raw_text[len('json\n'):].strip()
        elif raw_text.lower().startswith('json'):
            raw_text = raw_text[len('json'):].strip()
        
        result = json.loads(raw_text)
        result["notes"] = f"[PDF ì›ë³¸ ë¶„ì„] {result.get('notes', '')}"
        return result
        
    except Exception as e:
        print(f"âŒ PDF ì›ë³¸ ëŒ€ì‚¬ ì‹¤íŒ¨: {e}", flush=True)
        return {"overall_status": "NEEDS_REVIEW", "notes": f"PDF ì›ë³¸ ëŒ€ì‚¬ ì˜¤ë¥˜: {e}"}

def save_results_to_excel(df_results, output_path, sheet_name='AI_ëŒ€ì‚¬ê²°ê³¼'):
    """ê²°ê³¼ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥"""
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    try:
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            df_results.to_excel(writer, sheet_name=sheet_name, index=False)
        print(f"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}", flush=True)
        return True
    except Exception as e:
        print(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}", flush=True)
        return False

# ì—‘ì…€ ì•ŒíŒŒë²³ â†’ ì¸ë±ìŠ¤ ë³€í™˜ í•¨ìˆ˜
def column_to_index(column_str):
    column_str = column_str.upper()
    result = 0
    for char in column_str:
        result = result * 26 + (ord(char) - ord('A') + 1)
    return result - 1

# ì—‘ì…€ í—¤ë”-ì•ŒíŒŒë²³ ë§¤í•‘ ì§„ë‹¨ í•¨ìˆ˜
# config_columns: configì—ì„œ ì‚¬ìš©í•˜ëŠ” ì»¬ëŸ¼ ì•ŒíŒŒë²³ dict
# file_path: ì§„ë‹¨í•  ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
# sheet_name: ì‹œíŠ¸ëª…(ê¸°ë³¸ê°’ None)
def debug_excel_header(file_path, config_columns, sheet_name=None):
    import pandas as pd
    try:
        df = pd.read_excel(file_path, nrows=1, sheet_name=sheet_name)  # í—¤ë”ë§Œ ì½ê¸°
        if isinstance(df, dict):  # ì—¬ëŸ¬ ì‹œíŠ¸ ë°˜í™˜ì‹œ ì²« ì‹œíŠ¸ ì‚¬ìš©
            df = list(df.values())[0]
        headers = list(df.columns)
        print("\n[ì—‘ì…€ í—¤ë” ì§„ë‹¨ ê²°ê³¼]")
        print("ì—‘ì…€ íŒŒì¼ í—¤ë”:", headers)
        for key, col_alpha in config_columns.items():
            idx = column_to_index(col_alpha)
            if idx < len(headers):
                actual_header = headers[idx]
                print(f"[{key}] config: {col_alpha} â†’ ì—‘ì…€ í—¤ë”: '{actual_header}'")
            else:
                print(f"[{key}] config: {col_alpha} â†’ âŒ ì—‘ì…€ì— í•´ë‹¹ ì—´ ì—†ìŒ (ì¸ë±ìŠ¤ {idx})")
    except Exception as e:
        print(f"[ì§„ë‹¨ ì˜¤ë¥˜] ì—‘ì…€ í—¤ë” ì§„ë‹¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def run_ai_reconciliation_gemini(
    input_excel_path=None,
    output_dir=None,
    ocr_json_dir=None,
    original_pdf_dir=None,  # ì¦ë¹™ì›ë³¸ í´ë” ì¶”ê°€
    doc_no_column_name='Doc_No',
    progress_callback=None,
    stop_flag=None
):
    print(f"[í•¨ìˆ˜] run_ai_reconciliation_gemini ì‹œì‘", flush=True)
    print(f"[ë§¤ê°œë³€ìˆ˜] input_excel_path: {input_excel_path}", flush=True)
    print(f"[ë§¤ê°œë³€ìˆ˜] ocr_json_dir: {ocr_json_dir}", flush=True)
    print(f"[ë§¤ê°œë³€ìˆ˜] original_pdf_dir: {original_pdf_dir}", flush=True)
    print(f"[ë§¤ê°œë³€ìˆ˜] output_dir: {output_dir}", flush=True)
    print(f"[ë§¤ê°œë³€ìˆ˜] doc_no_column_name: {doc_no_column_name}", flush=True)
    """
    Gemini AI ëŒ€ì‚¬ ì‹¤í–‰ í•¨ìˆ˜
    
    Args:
        input_excel_path: ì…ë ¥ ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
        output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        ocr_json_dir: OCR JSON íŒŒì¼ ë””ë ‰í† ë¦¬
        doc_no_column_name: ì „í‘œë²ˆí˜¸ ì»¬ëŸ¼ëª…
        progress_callback: ì§„í–‰ë¥  ì½œë°± í•¨ìˆ˜
        stop_flag: ì¤‘ë‹¨ í”Œë˜ê·¸
    """
    # í•„ìˆ˜ ê²½ë¡œ ê²€ì¦
    if input_excel_path is None:
        print("âŒ ì˜¤ë¥˜: ì…ë ¥ ì—‘ì…€ íŒŒì¼ ê²½ë¡œê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", flush=True)
        return False
    if output_dir is None:
        print("âŒ ì˜¤ë¥˜: ì¶œë ¥ ë””ë ‰í† ë¦¬ê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", flush=True)
        return False
    if ocr_json_dir is None:
        print("âŒ ì˜¤ë¥˜: OCR JSON ë””ë ‰í† ë¦¬ê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", flush=True)
        return False
    if original_pdf_dir is None:
        print("âŒ ì˜¤ë¥˜: ì¦ë¹™ì›ë³¸ ë””ë ‰í† ë¦¬ê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", flush=True)
        return False
    
    # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ì„¤ì • (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
    timestamp = datetime.now().strftime('%Y%m%d%H%M')  # YYYYMMDDHHMM í˜•ì‹
    output_excel_filename = f'ë§¤ì¶œì¦ë¹™ëŒ€ì‚¬ê²°ê³¼_Gemini_{timestamp}.xlsx'
    output_excel_path = os.path.join(output_dir, output_excel_filename)
    
    # ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ ìë™ ê°ì§€ (í”„ë¡œê·¸ë¨ ì¬ì‹œì‘ ì‹œì—ë„ ê°ì§€)
    existing_checkpoints = []
    try:
        for file in os.listdir(output_dir):
            if file.startswith("checkpoint_Gemini_") and file.endswith(".json"):
                file_path = os.path.join(output_dir, file)
                file_time = os.path.getmtime(file_path)
                existing_checkpoints.append((file, file_time))
    except Exception as e:
        print(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ìŠ¤ìº” ì¤‘ ì˜¤ë¥˜: {e}", flush=True)
    
    checkpoint_data = None
    resume_from_index = 0
    completed_docs = []
    
    # ê°€ì¥ ìµœê·¼ ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°
    if existing_checkpoints:
        # íŒŒì¼ ìˆ˜ì • ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ ìµœê·¼ ì²´í¬í¬ì¸íŠ¸ ì„ íƒ
        latest_checkpoint = max(existing_checkpoints, key=lambda x: x[1])
        checkpoint_filename = latest_checkpoint[0]
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ (checkpoint_Gemini_202501171430.json â†’ 202501171430)
        timestamp_from_file = checkpoint_filename.replace("checkpoint_Gemini_", "").replace(".json", "")
        
        print(f"ğŸ“‚ ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ ë°œê²¬: {checkpoint_filename}", flush=True)
        checkpoint_data = load_checkpoint(output_dir, timestamp_from_file)
        
        if checkpoint_data:
            print(f"ğŸ“‚ ì²´í¬í¬ì¸íŠ¸ ì •ë³´: {checkpoint_data['completed_count']}/{checkpoint_data['total_count']} ì™„ë£Œ", flush=True)
            resume_from_index = checkpoint_data['completed_count']
            completed_docs = checkpoint_data['completed_docs']
            print(f"ğŸ”„ {resume_from_index}ë²ˆì§¸ ì „í‘œë¶€í„° ì´ì–´ì„œ ì§„í–‰í•©ë‹ˆë‹¤.", flush=True)
            
            # í˜„ì¬ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ì„¤ì •
            timestamp = timestamp_from_file
        else:
            print(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨, ìƒˆë¡œ ì‹œì‘í•©ë‹ˆë‹¤.", flush=True)
    else:
        print(f"ğŸ“‚ ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ì‹œì‘í•©ë‹ˆë‹¤.", flush=True)
    
    print(f"[ì‹œì‘] ë§¤ì¶œ ì¦ë¹™ ëŒ€ì‚¬ ì‹œì‘ (Gemini) - 2ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ - {datetime.now().strftime('%H:%M:%S')}", flush=True)
    print(f"[íŒŒì¼] ì…ë ¥ íŒŒì¼: {input_excel_path}", flush=True)
    print(f"[í´ë”] OCR í´ë”: {ocr_json_dir}", flush=True)
    print(f"[í´ë”] ì¦ë¹™ì›ë³¸ í´ë”: {original_pdf_dir}", flush=True)
    print(f"[í´ë”] ì¶œë ¥ í´ë”: {output_dir}", flush=True)

    # 1. Gemini API ì´ˆê¸°í™”
    print(f"ğŸ” Gemini API ì´ˆê¸°í™” ì‹œì‘: {datetime.now().strftime('%H:%M:%S')}", flush=True)
    gemini_model = initialize_gemini_api()
    if gemini_model is None:
        print(f"âŒ Gemini API ì´ˆê¸°í™” ì‹¤íŒ¨: {datetime.now().strftime('%H:%M:%S')}", flush=True)
        return False
    print(f"âœ… Gemini API ì´ˆê¸°í™” ì™„ë£Œ: {datetime.now().strftime('%H:%M:%S')}", flush=True)

    # 2. ì›ë³¸ ì—‘ì…€ íŒŒì¼ ë¡œë“œ
    df_original = load_excel_robustly(input_excel_path)

    if df_original is None:
        print("ì—‘ì…€ íŒŒì¼ì„ ë¡œë“œí•˜ì§€ ëª»í•˜ì—¬ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.", flush=True)
        return False

    # 3. ì „í‘œë²ˆí˜¸ ì»¬ëŸ¼ í™•ì¸ ë° í•„í„°ë§
    if doc_no_column_name in df_original.columns:
        # í•„í„°ë§í•  Doc_No ê°’ë“¤ì„ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ì˜ (ì—‘ì…€ì˜ 'ì´í•©ê³„'ì™€ ê°™ì€ ê°’). ëŒ€ì†Œë¬¸ì ë¬´ì‹œë¥¼ ìœ„í•´ .lower() ì‚¬ìš©
        doc_nos_to_exclude = ['ì´í•©ê³„', 'í•©ê³„', 'summary', 'total'] # ì‹¤ì œ ì—‘ì…€ì— ìˆëŠ” ì§‘ê³„ ê°’ë“¤ì„ ì¶”ê°€í•˜ì„¸ìš”.
        
        # Doc_No ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê³  ì†Œë¬¸ìë¡œ ë§Œë“  í›„ í•„í„°ë§
        df_original_filtered = df_original[~df_original[doc_no_column_name].astype(str).str.lower().isin(doc_nos_to_exclude)].copy()
        
        if len(df_original_filtered) < len(df_original):
            print(f"âœ… ìœ íš¨í•˜ì§€ ì•Šì€ Doc_No (ì´í•©ê³„ ë“±) í•„í„°ë§ ì™„ë£Œ. {len(df_original) - len(df_original_filtered)}ê±´ ì œì™¸ë¨.", flush=True)
            df_original = df_original_filtered # í•„í„°ë§ëœ DataFrameìœ¼ë¡œ êµì²´
        else:
            print("â„¹ï¸ Doc_No í•„í„°ë§ ê²°ê³¼, ì œì™¸ëœ ê±´ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.", flush=True)
    else:
        print(f"âš ï¸ ê²½ê³ : '{doc_no_column_name}' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ Doc_No í•„í„°ë§ì„ ê±´ë„ˆëœë‹ˆë‹¤.", flush=True)

    print(f"âœ… ì›ë³¸ ì—‘ì…€ ë¡œë”© ì™„ë£Œ: {input_excel_path} / ì²˜ë¦¬ ëŒ€ìƒ ê±´ìˆ˜: {len(df_original)}", flush=True)

    # 4. ê²°ê³¼ DataFrame ì¤€ë¹„ (ì›ë³¸ ë°ì´í„°ë¥¼ ë³µì‚¬í•˜ì—¬ ì‹œì‘)
    df_results = df_original.copy()

    # 5. AI ëŒ€ì‚¬ ê²°ê³¼ ì»¬ëŸ¼ ì¶”ê°€ (ë§ˆì§€ë§‰ ì—´ ë‹¤ìŒë¶€í„°)
    for col in RECONCILIATION_COLUMNS:
        df_results[col] = ''
    
    # ì¦ë¹™ì—ì„œ ì½ì–´ì˜¨ ì‹¤ì œ ê°’ë“¤ì„ í‘œì‹œí•  ì»¬ëŸ¼ë“¤ ì¶”ê°€
    for col in EVIDENCE_VALUE_COLUMNS:
        df_results[col] = ''
    
    # ì²´í¬í¬ì¸íŠ¸ê°€ ìˆìœ¼ë©´ ê¸°ì¡´ ê²°ê³¼ íŒŒì¼ì—ì„œ ë³µì›
    if checkpoint_data:
        try:
            # ê¸°ì¡´ ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
            existing_result_files = [f for f in os.listdir(output_dir) 
                                   if f.startswith(f"ë§¤ì¶œì¦ë¹™ëŒ€ì‚¬ê²°ê³¼_Gemini_{timestamp}") and f.endswith('.xlsx')]
            
            if existing_result_files:
                # ê°€ì¥ ìµœê·¼ íŒŒì¼ ì‚¬ìš©
                latest_file = max(existing_result_files, key=lambda x: os.path.getmtime(os.path.join(output_dir, x)))
                existing_result_path = os.path.join(output_dir, latest_file)
                
                print(f"ğŸ“‚ ê¸°ì¡´ ê²°ê³¼ íŒŒì¼ ë¡œë“œ: {existing_result_path}", flush=True)
                existing_df = load_excel_robustly(existing_result_path)
                
                if existing_df is not None:
                    # ê¸°ì¡´ ê²°ê³¼ë¥¼ í˜„ì¬ DataFrameì— ë³‘í•©
                    for col in RECONCILIATION_COLUMNS + EVIDENCE_VALUE_COLUMNS:
                        if col in existing_df.columns:
                            df_results[col] = existing_df[col]
                    
                    print(f"âœ… ê¸°ì¡´ ê²°ê³¼ ë³µì› ì™„ë£Œ: {len(completed_docs)}ê±´", flush=True)
                else:
                    print(f"âš ï¸ ê¸°ì¡´ ê²°ê³¼ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨, ìƒˆë¡œ ì‹œì‘í•©ë‹ˆë‹¤.", flush=True)
        except Exception as e:
            print(f"âš ï¸ ê¸°ì¡´ ê²°ê³¼ ë³µì› ì¤‘ ì˜¤ë¥˜: {e}, ìƒˆë¡œ ì‹œì‘í•©ë‹ˆë‹¤.", flush=True)

    # 6. ê° ì „í‘œ(Doc_No) ì²˜ë¦¬ ë£¨í”„ (OCR JSON íŒŒì¼ ì—°ë™ ë° ì‹¤ì œ Gemini API í˜¸ì¶œ)
    total_docs = len(df_original)
    no_evidence_docs = []  # ì¦ë¹™ì´ ì—†ëŠ” ì „í‘œë²ˆí˜¸ë“¤ì„ ìˆ˜ì§‘
    processed_docs = 0     # ì‹¤ì œ ì²˜ë¦¬ëœ ì „í‘œ ìˆ˜
    
    for index, row_data in df_original.iterrows(): # í•„í„°ë§ëœ df_originalì„ ìˆœíšŒí•©ë‹ˆë‹¤.
        # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì´ì–´ì„œ ì§„í–‰í•˜ëŠ” ê²½ìš°, ì´ë¯¸ ì™„ë£Œëœ ì „í‘œëŠ” ê±´ë„ˆë›°ê¸°
        if index < resume_from_index:
            continue
            
        # ì¤‘ë‹¨ í”Œë˜ê·¸ í™•ì¸
        if stop_flag and stop_flag.get():
            print("â¹ï¸ AI ëŒ€ì‚¬ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.", flush=True)
            break
            
        current_doc_no = str(row_data[doc_no_column_name]) # ì „í‘œë²ˆí˜¸ëŠ” ë¬¸ìì—´ë¡œ ì²˜ë¦¬í•˜ëŠ” ê²ƒì´ ì•ˆì „í•©ë‹ˆë‹¤.

        # ì§„í–‰ë¥  ì½œë°± í˜¸ì¶œ (ì‹œì‘ ì‹œ)
        if progress_callback:
            progress_callback(index + 1, total_docs, current_doc_no)

        # ì „ì²´ ì „í‘œ ì²˜ë¦¬ ê³¼ì •ì„ try-exceptë¡œ ê°ì‹¸ì„œ ì˜¤ë¥˜ ë°œìƒ ì‹œ ë‹¤ìŒ ì „í‘œë¡œ ì§„í–‰
        try:
            # 7. í•´ë‹¹ ì „í‘œì— ë§ëŠ” OCR ê²°ê³¼ JSON íŒŒì¼ ë¡œë“œ
            ocr_json_file_path = os.path.join(ocr_json_dir, f"{current_doc_no}.json") # ì „í‘œë²ˆí˜¸.json íŒŒì¼ëª… ê°€ì •

            ocr_data = None
            gemini_result = {} # Gemini ê²°ê³¼ ì´ˆê¸°í™” (API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’)
            
            try:
                with open(ocr_json_file_path, 'r', encoding='utf-8') as f:
                    ocr_data = json.load(f)
                # ì¦ë¹™ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ìƒì„¸ ë¡œê·¸ ì¶œë ¥
                print(f"\n[AI] Gemini í˜¸ì¶œ ì¤‘: Doc_No {current_doc_no} ({index + 1}/{total_docs})", flush=True)
                print(f"âœ… OCR JSON íŒŒì¼ ë¡œë”© ì™„ë£Œ: {ocr_json_file_path}", flush=True)
            except FileNotFoundError:
                # ì¦ë¹™ì´ ì—†ëŠ” ê²½ìš° ê°œë³„ ë¡œê·¸ ëŒ€ì‹  ìˆ˜ì§‘ë§Œ
                no_evidence_docs.append(current_doc_no)
                gemini_result = {"overall_status": "NO_EVIDENCE", "notes": "OCR ë°ì´í„° íŒŒì¼ ì—†ìŒ"}
                ocr_data = None # OCR ë°ì´í„°ê°€ ì—†ìŒì„ ëª…ì‹œ
                # ë‹¤ìŒ ì „í‘œë¡œ ë„˜ì–´ê°€ê¸° ìœ„í•´ continue ëŒ€ì‹  DataFrame ì—…ë°ì´íŠ¸ í›„ ê³„ì†
            except json.JSONDecodeError:
                print(f"âŒ ì˜¤ë¥˜: OCR JSON íŒŒì¼ '{ocr_json_file_path}'ì˜ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ ì „í‘œëŠ” ê±´ë„ˆëœë‹ˆë‹¤.", flush=True)
                gemini_result = {"overall_status": "NEEDS_REVIEW", "notes": "OCR ë°ì´í„° JSON í˜•ì‹ ì˜¤ë¥˜"}
                ocr_data = None
            except Exception as e:
                print(f"âŒ OCR JSON íŒŒì¼ ë¡œë”© ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}", flush=True)
                gemini_result = {"overall_status": "NEEDS_REVIEW", "notes": f"OCR ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}"}
                ocr_data = None

            # 8. Gemini APIì— ë³´ë‚¼ í”„ë¡¬í”„íŠ¸ êµ¬ì„± ë° ì‹¤ì œ í˜¸ì¶œ
            if ocr_data is not None: # OCR ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œëœ ê²½ìš°ì—ë§Œ Gemini í˜¸ì¶œ ì‹œë„
                processed_docs += 1  # ì‹¤ì œ ì²˜ë¦¬ëœ ì „í‘œ ìˆ˜ ì¦ê°€
                erp_info = row_data.to_dict() # ì—‘ì…€ í•œ ì¤„ì˜ ëª¨ë“  ERP ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ
                
                # Pandas Timestamp ê°ì²´ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ ë¬¸ìì—´ë¡œ ë³€í™˜ (TypeError í•´ê²°)
                serializable_erp_info = {}
                for key, value in erp_info.items():
                    try:
                        if pd.isna(value) or value is pd.NaT:
                            # NaT ë˜ëŠ” NaN ê°’ì€ ë¹ˆ ë¬¸ìì—´ë¡œ ì²˜ë¦¬
                            serializable_erp_info[key] = ""
                        elif isinstance(value, pd.Timestamp):
                            serializable_erp_info[key] = value.isoformat() # ISO 8601 í˜•ì‹ ë¬¸ìì—´ë¡œ ë³€í™˜
                        else:
                            serializable_erp_info[key] = value
                    except Exception as e:
                        # ê¸°íƒ€ ì§ë ¬í™” ë¶ˆê°€ëŠ¥í•œ ê°’ë“¤ì€ ë¬¸ìì—´ë¡œ ë³€í™˜
                        print(f"âš ï¸ ì§ë ¬í™” ì˜¤ë¥˜ (Doc_No: {current_doc_no}, ì»¬ëŸ¼: {key}): {e}", flush=True)
                        serializable_erp_info[key] = str(value) if value is not None else ""

                all_parsed_texts = []
                if 'documents' in ocr_data and isinstance(ocr_data['documents'], list):
                    for doc in ocr_data['documents']:
                        if 'parsed_text' in doc and isinstance(doc['parsed_text'], str):
                            all_parsed_texts.append(doc['parsed_text'])
                
                combined_ocr_text = "\n\n--- OCR Evidence Documents ---\n\n" + "\n\n".join(all_parsed_texts)

                # English prompt to reduce token usage
                json_response_example = json.dumps({
                  "amount_match": "MATCHED",
                  "quantity_match": "MATCHED", 
                  "date_match": "MATCHED",
                  "customer_match": "MATCHED",
                  "overall_status": "MATCHED",
                  "evidence_amount": "1,000,000 KRW",
                  "evidence_quantity": "100 units",
                  "evidence_date": "2024-01-15",
                  "evidence_customer": "ABC Company Ltd.",
                  "notes": "All data matches with evidence documents"
                }, indent=2)

                gemini_prompt = (
                    f"Compare ERP transaction data with OCR evidence documents.\n\n"
                    f"**Reconciliation Rules:**\n"
                    f"- Amount: Compare absolute values (ERP negative amounts = positive in evidence for sales specification)\n"
                    f"- Quantity: Exact match required\n"
                    f"- Date: Check revenue recognition date based on Incoterms\n"
                    f"- Customer: Compare customer/supplier name\n"
                    f"- Overall: Overall assessment\n"
                    f"- Notes: Key findings, discrepancies, and special comments\n\n"
                    f"**Date Matching Priority (ë§¤ì¶œì¼ì ê¸°ì¤€):**\n"
                    f"1. **ë§¤ì¶œì¼ì (P_Date)**: ERPì˜ ë§¤ì¶œì¼ìì™€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ë‚ ì§œë¥¼ ìš°ì„  ì°¾ê¸°\n"
                    f"2. **ìˆ˜ì¶œì‹ ê³ ì¼**: ìˆ˜ì¶œì‹ ê³ í•„ì¦ì˜ ë‚ ì§œëŠ” ì°¸ê³ ìš©ì´ë¯€ë¡œ, ë§¤ì¶œì¼ìì™€ ë‹¤ë¥´ë©´ ë¬´ì‹œ\n"
                    f"3. **ê¸°íƒ€ ë‚ ì§œ**: ì†¡ì¥ì¼ì, ë°°ì†¡ì¼ì ë“±ì€ ë§¤ì¶œì¼ìì™€ ì¼ì¹˜í•  ë•Œë§Œ ì‚¬ìš©\n"
                    f"4. **ë‚ ì§œ í˜•ì‹**: YYYY-MM-DD, YYYY.MM.DD, YYYY/MM/DD ë“± ë‹¤ì–‘í•œ í˜•ì‹ í™•ì¸\n"
                    f"5. **ì¼ì¹˜ íŒë‹¨**: ERP ë§¤ì¶œì¼ìì™€ ì¦ë¹™ì˜ ë‚ ì§œê°€ ì •í™•íˆ ì¼ì¹˜í•˜ë©´ MATCHED\n"
                    f"6. **ë¶ˆì¼ì¹˜ íŒë‹¨**: ë§¤ì¶œì¼ìì™€ ë‹¤ë¥¸ ë‚ ì§œë§Œ ìˆìœ¼ë©´ MISMATCHED\n\n"
                    f"**Revenue Recognition Date (Incoterms ê¸°ì¤€):**\n"
                    f"- C/F ì¡°ê±´ (CFR, CIF, CPT, CIP): ì„ ì ì¼ ê¸°ì¤€ ë§¤ì¶œì¸ì‹\n"
                    f"- EXW ì¡°ê±´: ê³µì¥ì¶œê³ ì¼ ê¸°ì¤€ ë§¤ì¶œì¸ì‹ (ê³µì¥ì¶œê³ ì¦/ì´ë©”ì¼)\n"
                    f"- F ì¡°ê±´ (FCA, FAS, FOB): ì„ ì ì¼ ë˜ëŠ” ìš´ì†¡ì¸ì¸ë„ì¼ ê¸°ì¤€\n"
                    f"- D ì¡°ê±´ (DAP, DPU, DDP): ë„ì°©ì¼ ë˜ëŠ” í•˜ì—­ì™„ë£Œì¼ ê¸°ì¤€\n\n"
                    f"**ì¸ì½”í…€ì¦ˆë³„ ë§¤ì¶œì¸ì‹ì¼ ìƒì„¸ ê¸°ì¤€:**\n"
                )
                
                # ì¸ì½”í…€ì¦ˆ ì„¤ì •ì„ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
                for incoterm, config in INCOTERMS_CONFIG.items():
                    gemini_prompt += f"- {incoterm}: {config['description']}\n"
                
                gemini_prompt += (
                    f"**Important Notes:**\n"
                    f"- For sales specification: ERP amounts are debit-based (negative = positive actual amount)\n"
                    f"- Use absolute values for amount comparison\n"
                    f"- **ë‚ ì§œ ë§¤ì¹­ ì‹œ ì£¼ì˜**: ìˆ˜ì¶œì‹ ê³ í•„ì¦ì˜ ë‚ ì§œëŠ” ìˆ˜ì¶œì‹ ê³ ì¼ì´ë¯€ë¡œ ë§¤ì¶œì¼ìì™€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ\n"
                    f"- **ì˜¬ë°”ë¥¸ ë‚ ì§œ ì„ íƒ**: ERP ë§¤ì¶œì¼ìì™€ ì¼ì¹˜í•˜ëŠ” ë‚ ì§œë¥¼ ì°¾ì•„ì•¼ í•¨\n"
                    f"- Check for date format variations (YYYY-MM-DD, YYYY.MM.DD, etc.)\n"
                    f"- Customer names may have slight variations (abbreviations, spacing)\n\n"
                    f"**Status Options:**\n"
                    f"- MATCHED: Data matches exactly or within acceptable tolerance\n"
                    f"- MISMATCHED: Clear discrepancy found\n"
                    f"- NEEDS_REVIEW: Requires manual review\n"
                    f"- NO_EVIDENCE: No supporting evidence found\n\n"
                    f"**Required Response Format:**\n"
                    f"You MUST include the actual values found in evidence documents:\n"
                    f"- evidence_amount: The actual amount found in evidence (e.g., '1,000,000 KRW')\n"
                    f"- evidence_quantity: The actual quantity found in evidence (e.g., '100 units')\n"
                    f"- evidence_date: The actual date found in evidence (e.g., '2024-01-15')\n"
                    f"- evidence_customer: The actual customer name found in evidence (e.g., 'ABC Company Ltd.')\n\n"
                    f"**Date Matching Instructions:**\n"
                    f"- ERP ë§¤ì¶œì¼ì(P_Date)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¦ë¹™ì—ì„œ ì¼ì¹˜í•˜ëŠ” ë‚ ì§œë¥¼ ì°¾ê¸°\n"
                    f"- ìˆ˜ì¶œì‹ ê³ í•„ì¦ì˜ ë‚ ì§œëŠ” ìˆ˜ì¶œì‹ ê³ ì¼ì´ë¯€ë¡œ ë§¤ì¶œì¼ìì™€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ\n"
                    f"- ì—¬ëŸ¬ ë‚ ì§œê°€ ìˆì„ ë•ŒëŠ” ë§¤ì¶œì¼ìì™€ ì¼ì¹˜í•˜ëŠ” ê²ƒì„ ìš°ì„  ì„ íƒ\n"
                    f"- ë§¤ì¶œì¼ìì™€ ì¼ì¹˜í•˜ëŠ” ë‚ ì§œê°€ ì—†ìœ¼ë©´ MISMATCHEDë¡œ íŒë‹¨\n\n"
                    f"For MISMATCHED items, provide detailed notes explaining:\n"
                    f"- What specific differences were found\n"
                    f"- Which values need to be checked\n"
                    f"- What actions should be taken for verification\n\n"
                    f"--- ERP Data ---\n{json.dumps(serializable_erp_info, indent=2, ensure_ascii=False)}\n\n"
                    f"--- Evidence Documents ---\n{combined_ocr_text}\n\n"
                    f"Return JSON with status for each category and evidence values.\n"
                    f"Example format:\n{json_response_example}\n"
                )
                
                # 9. ì‹¤ì œ Gemini API í˜¸ì¶œ
                try:
                    response = gemini_model.generate_content(gemini_prompt)
                    
                    # ì‘ë‹µì´ ë¹„ì–´ìˆê±°ë‚˜, í…ìŠ¤íŠ¸ê°€ ì—†ì„ ê²½ìš°ì— ëŒ€í•œ ì²˜ë¦¬
                    if not response.text:
                        raise ValueError("Gemini APIê°€ ë¹ˆ ì‘ë‹µì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")
                        
                    raw_gemini_text = response.text.strip() # ì‘ë‹µ í…ìŠ¤íŠ¸ì˜ ì•ë’¤ ê³µë°± ì œê±°
                    
                    # Geminiê°€ ì‘ë‹µì„ Markdown JSON ë¸”ë¡ìœ¼ë¡œ ê°ì‹¸ëŠ” ê²½ìš° ì²˜ë¦¬ (ë” ê°•ë ¥í•œ ì²˜ë¦¬)
                    raw_gemini_text = raw_gemini_text.replace('```json', '').replace('```', '').strip()
                    if raw_gemini_text.lower().startswith('json\n'):
                        raw_gemini_text = raw_gemini_text[len('json\n'):].strip()
                    elif raw_gemini_text.lower().startswith('json'):
                         raw_gemini_text = raw_gemini_text[len('json'):].strip()
                    
                    # Gemini ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ JSONìœ¼ë¡œ íŒŒì‹±
                    gemini_result = json.loads(raw_gemini_text)
                    
                    print(f"[ì™„ë£Œ] Gemini OCR ì‘ë‹µ ì™„ë£Œ (Doc_No: {current_doc_no})", flush=True)
                    
                    # ì§„í–‰ë¥  ì½œë°± í˜¸ì¶œ (OCR ì™„ë£Œ ì‹œ)
                    if progress_callback:
                        progress_callback(index + 1, total_docs, f"{current_doc_no} (OCR ì™„ë£Œ)")
                    
                    # í† í° ì‚¬ìš©ëŸ‰ ë¡œê·¸ ì¶œë ¥ (ì‘ë‹µ ë©”íƒ€ë°ì´í„°ê°€ ìˆì„ ê²½ìš°)
                    if hasattr(response, 'usage_metadata') and response.usage_metadata:
                        print(f"   - ì…ë ¥ í† í°: {response.usage_metadata.prompt_token_count}, ì¶œë ¥ í† í°: {response.usage_metadata.candidates_token_count}", flush=True)
                    else:
                        print("   - í† í° ì‚¬ìš©ëŸ‰ ì •ë³´ ì—†ìŒ (ì‘ë‹µ ë©”íƒ€ë°ì´í„° ë¶€ì¬).", flush=True)

                    # 2ë‹¨ê³„: OCR ê²°ê³¼ê°€ ë¶ˆí™•ì‹¤í•œ ê²½ìš° PDF ì›ë³¸ìœ¼ë¡œ ì¬ê²€ì¦
                    if gemini_result.get("overall_status") in ["NEEDS_REVIEW", "MISMATCHED"]:
                        print(f"ğŸ”„ OCR ê²°ê³¼ ë¶ˆí™•ì‹¤ - PDF ì›ë³¸ìœ¼ë¡œ ì¬ê²€ì¦ ì‹œì‘ (Doc_No: {current_doc_no})", flush=True)
                        
                        try:
                            # í•´ë‹¹ ì „í‘œë²ˆí˜¸ì˜ PDF ì›ë³¸ íŒŒì¼ë“¤ ì°¾ê¸°
                            pdf_files = find_original_pdf_files(current_doc_no, original_pdf_dir)
                            
                            if pdf_files:
                                print(f"   - PDF ì›ë³¸ íŒŒì¼ ë°œê²¬: {len(pdf_files)}ê°œ", flush=True)
                                for pdf_file in pdf_files:
                                    print(f"     â€¢ {os.path.basename(pdf_file)}", flush=True)
                                
                                # PDF ì›ë³¸ìœ¼ë¡œ ì¬ê²€ì¦
                                pdf_result = reconcile_with_pdf_original(serializable_erp_info, pdf_files, gemini_model)
                                
                                # PDF ê²°ê³¼ê°€ ë” í™•ì‹¤í•œ ê²½ìš° OCR ê²°ê³¼ë¥¼ ëŒ€ì²´
                                if pdf_result.get("overall_status") in ["MATCHED", "MISMATCHED"]:
                                    print(f"   âœ… PDF ì›ë³¸ ë¶„ì„ ì™„ë£Œ - OCR ê²°ê³¼ ëŒ€ì²´", flush=True)
                                    gemini_result = pdf_result
                                    
                                    # ì§„í–‰ë¥  ì½œë°± í˜¸ì¶œ (PDF ë¶„ì„ ì™„ë£Œ ì‹œ)
                                    if progress_callback:
                                        progress_callback(index + 1, total_docs, f"{current_doc_no} (PDF ë¶„ì„ ì™„ë£Œ)")
                                else:
                                    print(f"   âš ï¸ PDF ì›ë³¸ ë¶„ì„ë„ ë¶ˆí™•ì‹¤ - OCR ê²°ê³¼ ìœ ì§€", flush=True)
                            else:
                                print(f"   âš ï¸ PDF ì›ë³¸ íŒŒì¼ ì—†ìŒ - OCR ê²°ê³¼ ìœ ì§€", flush=True)
                        except Exception as pdf_error:
                            print(f"   âš ï¸ PDF ì›ë³¸ ì¬ê²€ì¦ ì¤‘ ì˜¤ë¥˜ (Doc_No: {current_doc_no}): {pdf_error}", flush=True)
                            # PDF ì¬ê²€ì¦ ì‹¤íŒ¨ ì‹œ OCR ê²°ê³¼ ìœ ì§€

                    # API í˜¸ì¶œ ê°„ ì ì‹œ ëŒ€ê¸° (ë¬´ë£Œ ì‚¬ìš©ëŸ‰ í•œë„ ì´ˆê³¼ ë°©ì§€ ë° ì•ˆì •ì ì¸ í˜¸ì¶œì„ ìœ„í•¨)
                    time.sleep(1) # 1ì´ˆ ëŒ€ê¸° (í•„ìš”ì— ë”°ë¼ ì¡°ì ˆ)

                except json.JSONDecodeError as json_error:
                    print(f"âŒ Gemini ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜ (Doc_No: {current_doc_no}): Geminiê°€ ìœ íš¨í•œ JSONì„ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì›ë³¸ í…ìŠ¤íŠ¸ ì‹œì‘: '{raw_gemini_text[:200]}'...", flush=True)
                    gemini_result = {"overall_status": "NEEDS_REVIEW", "notes": f"Gemini ì‘ë‹µ JSON íŒŒì‹± ì˜¤ë¥˜: {json_error}"}
                except Exception as e:
                    print(f"âŒ Gemini API í˜¸ì¶œ ì‹¤íŒ¨ (Doc_No: {current_doc_no}): {e}", flush=True)
                    gemini_result = {"overall_status": "NEEDS_REVIEW", "notes": f"API í˜¸ì¶œ ì˜¤ë¥˜: {e}"}
            else:
                # OCR ë°ì´í„° ë¡œë”© ìì²´ê°€ ì‹¤íŒ¨í•œ ê²½ìš° (gemini_resultëŠ” ì´ë¯¸ ìœ„ì—ì„œ ì„¤ì •ë¨)
                print(f"âš ï¸ Doc_No {current_doc_no}: OCR ë°ì´í„° ë¬¸ì œë¡œ Gemini í˜¸ì¶œ ê±´ë„ˆëœ€.", flush=True)

            # 10. df_results DataFrameì˜ í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ í–‰ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
            row_idx_in_results = index

            # ê° ëŒ€ì‚¬ í•­ëª© ê²°ê³¼ ì—…ë°ì´íŠ¸
            for col in RECONCILIATION_COLUMNS:
                if col == "ì „ì²´ê²°ê³¼":
                    # ì „ì²´ê²°ê³¼ ì»¬ëŸ¼ì€ overall_statusì˜ í•œê¸€ ë²„ì „
                    if "overall_status" in gemini_result:
                        status = gemini_result["overall_status"]
                        
                        # ì˜ì–´ ìƒíƒœë¥¼ í•œê¸€ë¡œ ë³€í™˜
                        korean_status = ""
                        if status == "MATCHED":
                            korean_status = "ì¼ì¹˜"
                        elif status == "MISMATCHED":
                            korean_status = "ë¶ˆì¼ì¹˜"
                        elif status == "NEEDS_REVIEW":
                            korean_status = "í™•ì¸í•„ìš”"
                        elif status == "NO_EVIDENCE":
                            korean_status = "ì¦ë¹™ì—†ìŒ"
                        else: # ê¸°íƒ€ ìƒíƒœ
                            korean_status = "í™•ì¸í•„ìš”"

                        df_results.loc[row_idx_in_results, col] = korean_status
                    else:
                        df_results.loc[row_idx_in_results, col] = 'ë°ì´í„°ì—†ìŒ'
                elif col in gemini_result:
                    status = gemini_result[col]
                    
                    # ì˜ì–´ ìƒíƒœë¥¼ í•œê¸€ë¡œ ë³€í™˜
                    korean_status = ""
                    if status == "MATCHED":
                        korean_status = "ì¼ì¹˜"
                    elif status == "MISMATCHED":
                        korean_status = "ë¶ˆì¼ì¹˜"
                    elif status == "NEEDS_REVIEW":
                        korean_status = "í™•ì¸í•„ìš”"
                    elif status == "NO_EVIDENCE":
                        korean_status = "ì¦ë¹™ì—†ìŒ"
                    else: # ê¸°íƒ€ ìƒíƒœ
                        korean_status = "í™•ì¸í•„ìš”"

                    df_results.loc[row_idx_in_results, col] = korean_status
                else:
                    # Gemini ê²°ê³¼ì— í•´ë‹¹ ì¹´í…Œê³ ë¦¬ê°€ ì—†ëŠ” ê²½ìš°
                    df_results.loc[row_idx_in_results, col] = 'ë°ì´í„°ì—†ìŒ'
            
            # ì¦ë¹™ì—ì„œ ì½ì–´ì˜¨ ì‹¤ì œ ê°’ë“¤ ì—…ë°ì´íŠ¸
            for col in EVIDENCE_VALUE_COLUMNS:
                if col in gemini_result:
                    evidence_value = gemini_result[col]
                    df_results.loc[row_idx_in_results, col] = evidence_value
                else:
                    # Gemini ê²°ê³¼ì— í•´ë‹¹ ì¦ë¹™ ê°’ì´ ì—†ëŠ” ê²½ìš°
                    df_results.loc[row_idx_in_results, col] = ''

            print(f"âœ… Doc_No {current_doc_no} ê²°ê³¼ DataFrame ì—…ë°ì´íŠ¸ ì™„ë£Œ.", flush=True)
            
            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (CHECKPOINT_INTERVALë§ˆë‹¤)
            processed_docs += 1
            
            # ì‹¤ì‹œê°„ ì§„í–‰ ì¤‘ì¸ ê²°ê³¼ íŒŒì¼ ì €ì¥ (ë§¤ë²ˆ ì—…ë°ì´íŠ¸)
            save_intermediate_results(df_results, output_dir, timestamp, "")
            
            # ì£¼ê¸°ì  ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (CHECKPOINT_INTERVALë§ˆë‹¤)
            if processed_docs % CHECKPOINT_INTERVAL == 0:
                save_checkpoint(df_results, output_dir, processed_docs, total_docs, timestamp)
                save_intermediate_results(df_results, output_dir, timestamp, f"{processed_docs}ê±´ì™„ë£Œ")
                print(f"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ë° ì¤‘ê°„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ ({processed_docs}/{total_docs})", flush=True)
            
        except Exception as e:
            # ì „ì²´ ì „í‘œ ì²˜ë¦¬ ê³¼ì •ì—ì„œ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ ì‹œ
            print(f"âŒ ì „í‘œ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ (Doc_No: {current_doc_no}): {e}", flush=True)
            print(f"âš ï¸ í•´ë‹¹ ì „í‘œë¥¼ ê±´ë„ˆë›°ê³  ë‹¤ìŒ ì „í‘œë¡œ ì§„í–‰í•©ë‹ˆë‹¤.", flush=True)
            
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ê²°ê³¼ ì„¤ì •
            gemini_result = {"overall_status": "NEEDS_REVIEW", "notes": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"}
            
            # DataFrame ì—…ë°ì´íŠ¸ (ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ê²°ê³¼ëŠ” ê¸°ë¡)
            row_idx_in_results = index
            for col in RECONCILIATION_COLUMNS:
                if col == "ì „ì²´ê²°ê³¼":
                    df_results.loc[row_idx_in_results, col] = "í™•ì¸í•„ìš”"
                else:
                    df_results.loc[row_idx_in_results, col] = "í™•ì¸í•„ìš”"
            
            for col in EVIDENCE_VALUE_COLUMNS:
                df_results.loc[row_idx_in_results, col] = ""
            
            print(f"âœ… Doc_No {current_doc_no} ì˜¤ë¥˜ ì²˜ë¦¬ ì™„ë£Œ - ë‹¤ìŒ ì „í‘œë¡œ ì§„í–‰", flush=True)

    # 11. ì¦ë¹™ì´ ì—†ëŠ” ì „í‘œë“¤ì— ëŒ€í•œ ìš”ì•½ ë¡œê·¸ ì¶œë ¥
    if no_evidence_docs:
        print(f"\nğŸ“Š ì¦ë¹™ì´ ì—†ëŠ” ì „í‘œ ìš”ì•½:", flush=True)
        print(f"   - ì´ {len(no_evidence_docs)}ê±´ì˜ ì „í‘œì— ì¦ë¹™ì´ ì—†ìŠµë‹ˆë‹¤.", flush=True)
        if len(no_evidence_docs) <= 10:
            print(f"   - ì „í‘œë²ˆí˜¸: {', '.join(no_evidence_docs)}", flush=True)
        else:
            print(f"   - ì „í‘œë²ˆí˜¸ (ì²˜ìŒ 10ê°œ): {', '.join(no_evidence_docs[:10])}...", flush=True)
            print(f"   - ë‚˜ë¨¸ì§€ {len(no_evidence_docs) - 10}ê±´ì€ ìƒëµ", flush=True)
    
    print(f"\nğŸ“ˆ ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½:", flush=True)
    print(f"   - ì´ ì „í‘œ: {total_docs}ê±´", flush=True)
    print(f"   - AI ì²˜ë¦¬: {processed_docs}ê±´", flush=True)
    print(f"   - ì¦ë¹™ ì—†ìŒ: {len(no_evidence_docs)}ê±´", flush=True)

    # 12. ìµœì¢… DataFrameì„ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥
    try:
        save_results_to_excel(df_results, output_excel_path)
        
        # ìµœì¢… ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë° ì •ë¦¬
        save_checkpoint(df_results, output_dir, total_docs, total_docs, timestamp)
        save_intermediate_results(df_results, output_dir, timestamp, "ì™„ë£Œ")
        
        # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì •ë¦¬ (ìµœì¢… ì™„ë£Œ ì‹œ)
        checkpoint_file = os.path.join(output_dir, f"checkpoint_Gemini_{timestamp}.json")
        if os.path.exists(checkpoint_file):
            try:
                os.remove(checkpoint_file)
                print(f"ğŸ§¹ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ", flush=True)
            except Exception as e:
                print(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {e}", flush=True)
        
        print(f"ğŸ‰ AI ëŒ€ì‚¬ ì™„ë£Œ! ìµœì¢… ê²°ê³¼: {output_excel_path}", flush=True)
        return True
    except Exception as e:
        print(f"âŒ ì—‘ì…€ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", flush=True)
        return False

# ìŠ¤í¬ë¦½íŠ¸ë¡œ ì§ì ‘ ì‹¤í–‰ë  ë•Œì˜ ì²˜ë¦¬
if __name__ == "__main__":
    print(f"[ë””ë²„ê¹…] ëª…ë ¹í–‰ ì¸ìˆ˜ ê°œìˆ˜: {len(sys.argv)}", flush=True)
    for i, arg in enumerate(sys.argv):
        print(f"[ë””ë²„ê¹…] ì¸ìˆ˜[{i}]: {arg}", flush=True)
    
    # ëª…ë ¹í–‰ ì¸ìˆ˜ ì²˜ë¦¬ (2ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ ì§€ì›)
    if len(sys.argv) > 1:
        # ëª…ë ¹í–‰ì—ì„œ ì¸ìˆ˜ ë°›ê¸°
        input_path = sys.argv[1] if len(sys.argv) > 1 else None
        ocr_path = sys.argv[2] if len(sys.argv) > 2 else None
        original_path = sys.argv[3] if len(sys.argv) > 3 else None  # ì¦ë¹™ì›ë³¸ í´ë” ì¶”ê°€
        output_path = sys.argv[4] if len(sys.argv) > 4 else None
        doc_no_col = sys.argv[5] if len(sys.argv) > 5 else 'Doc_No'
        
        print(f"[ë””ë²„ê¹…] íŒŒì‹±ëœ ì¸ìˆ˜:", flush=True)
        print(f"  - input_path: {input_path}", flush=True)
        print(f"  - ocr_path: {ocr_path}", flush=True)
        print(f"  - original_path: {original_path}", flush=True)
        print(f"  - output_path: {output_path}", flush=True)
        print(f"  - doc_no_col: {doc_no_col}", flush=True)
        
        success = run_ai_reconciliation_gemini(
            input_excel_path=input_path,
            output_dir=output_path,
            ocr_json_dir=ocr_path,
            original_pdf_dir=original_path,  # ì¦ë¹™ì›ë³¸ í´ë” ì¶”ê°€
            doc_no_column_name=doc_no_col
        )
    else:
        # ê¸°ë³¸ê°’ìœ¼ë¡œ ì‹¤í–‰ (í•˜ë“œì½”ë”©ëœ ê²½ë¡œ ì‚¬ìš©)
        print("[ë””ë²„ê¹…] ê¸°ë³¸ê°’ìœ¼ë¡œ ì‹¤í–‰", flush=True)
        print("âš ï¸ ëª…ë ¹í–‰ ì¸ìˆ˜ê°€ ì—†ì–´ í•˜ë“œì½”ë”©ëœ ê²½ë¡œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.", flush=True)
        success = run_ai_reconciliation_gemini(
            input_excel_path='D:/CJ/11.ìë™í™”/ë§¤ì¶œì¦ë¹™ëŒ€ì‚¬/01_ì „í‘œëª©ë¡/ë§¤ì¶œëª…ì„¸ì„œ_í…ŒìŠ¤íŠ¸ìš©.xlsx',
            output_dir='D:/CJ/11.ìë™í™”/ë§¤ì¶œì¦ë¹™ëŒ€ì‚¬/05_AIëŒ€ì‚¬ê²°ê³¼/',
            ocr_json_dir='D:/CJ/11.ìë™í™”/ë§¤ì¶œì¦ë¹™ëŒ€ì‚¬/03_OCRê²°ê³¼_í…ŒìŠ¤íŠ¸/',
            original_pdf_dir='D:/CJ/11.ìë™í™”/ë§¤ì¶œì¦ë¹™ëŒ€ì‚¬/02_ì¦ë¹™ë‹¤ìš´ë¡œë“œ/'
        )
    
    if success:
        print("âœ… Gemini AI ëŒ€ì‚¬ ì™„ë£Œ! (2ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤)", flush=True)
    else:
        print("âŒ Gemini AI ëŒ€ì‚¬ ì‹¤íŒ¨!", flush=True)
        sys.exit(1)
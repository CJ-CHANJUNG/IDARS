# -*- coding: utf-8 -*-
"""
Smart Extraction Engine - Hybrid OCR + Gemini API
í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ìœ¼ë¡œ PDFì—ì„œ ë°ì´í„° ì¶”ì¶œ:
1. PyMuPDFë¡œ í…ìŠ¤íŠ¸ PDF ë¹ ë¥¸ ì²˜ë¦¬
2. ìŠ¤ìº” PDFëŠ” Tesseract OCR
3. BL, Invoiceë§Œ ì„ íƒì  ì²˜ë¦¬
4. Gemini APIë¡œ í•„ë“œ ì¶”ì¶œ + ì‹ ë¢°ë„ ê³„ì‚°
"""

import fitz  # PyMuPDF
import pytesseract
from PIL import Image
import io
import os
import asyncio
import json
import re
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import google.generativeai as genai

# Tesseract ê²½ë¡œ ì„¤ì •
TESSERACT_PATH = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
try:
    pytesseract.pytesseract.tesseract_cmd = TESSERACT_PATH
except:
    print("âš ï¸ Tesseract ê²½ë¡œ ì„¤ì • ì˜¤ë¥˜")

# OCR ì„ê³„ê°’
OCR_THRESHOLD = 100  # í…ìŠ¤íŠ¸ê°€ ì´ ê°’ë³´ë‹¤ ì ìœ¼ë©´ ìŠ¤ìº” PDFë¡œ ê°„ì£¼

# ë¬¸ì„œ íƒ€ì… ê²€ì¶œ íŒ¨í„´ (pdf_splitter.pyì—ì„œ ê°€ì ¸ì˜´)
DOCUMENT_PATTERNS = {
    'BL': [  # Bill of Lading
        (r'BILL\s*OF\s*LADING', 100),
        (r'WAYBILL', 100),
        (r'MULTIMODAL\s*TRANSPORT', 100),
        (r'SURRENDER', 95),
        (r'TELEX\s*RELEASE', 95),
        (r'PORT\s*OF\s*LOADING', 60),
        (r'PORT\s*OF\s*DISCHARGE', 60),
        (r'CLEAN\s*ON\s*BOARD', 70),
        (r'FREIGHT\s*PREPAID', 60),
    ],
    'INVOICE': [  # Commercial Invoice
        (r'COMMERCIAL\s*INVOICE', 100),
        (r'PROFORMA\s*INVOICE', 100),
        (r'INVOICE\s*NO', 80),
    ],
    'PACKING_LIST': [  # Packing List (í•„í„°ë§ìš©)
        (r'PACKING\s*LIST', 100),
        (r'DETAIL\s*OF\s*PACKING', 90),
    ],
}


class SmartExtractionEngine:
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.gemini_model = None
        self.extraction_config = None
        self.data_normalizer = None
        self._load_configs()
    
    def _load_configs(self):
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
            import sys
            from pathlib import Path
            project_root = Path(__file__).parent.parent.parent
            if str(project_root) not in sys.path:
                sys.path.insert(0, str(project_root))
            
            # Gemini API í‚¤ ë¡œë“œ
            from Config.api_config import GEMINI_API_KEY
            genai.configure(api_key=GEMINI_API_KEY)
            
            # ëª¨ë¸ ì„ íƒ (ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸ë¨)
            GEMINI_MODEL_NAME = 'models/gemini-2.5-flash'
            
            try:
                self.gemini_model = genai.GenerativeModel(GEMINI_MODEL_NAME)
                # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
                test_response = self.gemini_model.generate_content("Hello")
                if test_response and test_response.text:
                    print(f"âœ… Gemini API ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: {GEMINI_MODEL_NAME})")
                else:
                    raise Exception("í…ŒìŠ¤íŠ¸ ì‘ë‹µ ì—†ìŒ")
            except Exception as e:
                print(f"âš ï¸ {GEMINI_MODEL_NAME} ì‹¤íŒ¨: {e}")
                # ëŒ€ì²´ ëª¨ë¸ ì‹œë„ (ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤)
                fallback_models = [
                    'models/gemini-2.0-flash',
                    'models/gemini-2.5-pro',
                    'models/gemini-2.0-flash-exp'
                ]
                model_loaded = False
                
                for fallback_model in fallback_models:
                    try:
                        print(f"   ì‹œë„ ì¤‘: {fallback_model}")
                        self.gemini_model = genai.GenerativeModel(fallback_model)
                        test_response = self.gemini_model.generate_content("Hello")
                        if test_response and test_response.text:
                            print(f"âœ… Gemini API ì´ˆê¸°í™” ì™„ë£Œ (ëŒ€ì²´ ëª¨ë¸: {fallback_model})")
                            model_loaded = True
                            break
                    except Exception as fb_error:
                        print(f"   âŒ {fallback_model} ì‹¤íŒ¨: {fb_error}")
                        continue
                
                if not model_loaded:
                    print("\nğŸ’¡ í•´ê²° ë°©ë²•:")
                    print("   1. Google Cloud Consoleì—ì„œ 'Generative Language API' í™œì„±í™”")
                    print("   2. https://console.cloud.google.com/apis/library")
                    print("   3. API í‚¤ í™•ì¸: Config/api_config.py")
                    raise Exception("ëª¨ë“  Gemini ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
        except ImportError:
            print("âŒ Config/api_config.py íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. api_config.example.pyë¥¼ ë³µì‚¬í•˜ì—¬ API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
            raise
        except Exception as e:
            print(f"âŒ Gemini API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
        
        # ì¶”ì¶œ í•„ë“œ ì„¤ì • ë¡œë“œ
        try:
            config_path = Path(__file__).parent.parent.parent / 'Config' / 'extraction_config.json'
            with open(config_path, 'r', encoding='utf-8') as f:
                self.extraction_config = json.load(f)
            print("âœ… Extraction Config ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ extraction_config.json ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.extraction_config = {"default_fields": [], "optional_fields": [], "document_types": {}}
        
        # DataNormalizer ì´ˆê¸°í™”
        try:
            from backend.logic.data_normalizer import DataNormalizer
            self.data_normalizer = DataNormalizer()
            print("âœ… DataNormalizer ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ DataNormalizer ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.data_normalizer = None
    
    
    def detect_document_type(self, pdf_path: str, page_num: int) -> Tuple[str, str]:
        """
        ë¬¸ì„œ íƒ€ì… ê°ì§€ (íŒŒì¼ëª… ì ˆëŒ€ ìš°ì„ )
        """
        filename = os.path.basename(pdf_path).upper()
        
        # 1. íŒŒì¼ëª… ê¸°ë°˜ ë¶„ë¥˜ (ê°€ì¥ ê°•ë ¥í•œ ê·œì¹™)
        if "BILL_OF_LADING" in filename or "WAYBILL" in filename:
            print(f"   ğŸ¯ íŒŒì¼ëª… ê·œì¹™ ì ìš©: BL ({filename})")
            doc = fitz.open(pdf_path)
            page = doc[page_num]
            text = page.get_text()
            doc.close()
            return "BL", text
            
        if "COMMERCIAL_INVOICE" in filename or "INVOICE" in filename:
            # PACKING LISTëŠ” ì œì™¸
            if "PACKING" not in filename:
                print(f"   ğŸ¯ íŒŒì¼ëª… ê·œì¹™ ì ìš©: INVOICE ({filename})")
                doc = fitz.open(pdf_path)
                page = doc[page_num]
                text = page.get_text()
                doc.close()
                return "INVOICE", text
        
        # 2. íŒŒì¼ëª…ìœ¼ë¡œ ì‹ë³„ ë¶ˆê°€í•œ ê²½ìš°ì—ë§Œ ë‚´ìš© ë¶„ì„
        print(f"   âš ï¸ íŒŒì¼ëª… ê·œì¹™ ì‹¤íŒ¨, ë‚´ìš© ë¶„ì„ ì‹œë„: {filename}")
        try:
            doc = fitz.open(pdf_path)
            page = doc[page_num]
            text = page.get_text()
            doc.close()
            
            # í…ìŠ¤íŠ¸ê°€ ê±°ì˜ ì—†ìœ¼ë©´ ìŠ¤ìº” ë¬¸ì„œ
            if len(text.strip()) < OCR_THRESHOLD:
                return "SCAN_REQUIRED", text
            
            # Regex íŒ¨í„´ìœ¼ë¡œ ë¬¸ì„œ íƒ€ì… ê²€ì¶œ (ì ìˆ˜ ê¸°ë°˜)
            text_upper = text.upper()
            best_type = None
            best_conf = 0.0
            
            for doc_type, patterns in DOCUMENT_PATTERNS.items():
                for pattern, score in patterns:
                    if re.search(pattern, text_upper):
                        if score > best_conf:
                            best_conf = score
                            best_type = doc_type
            
            # ì‹ ë¢°ë„ê°€ 50 ë¯¸ë§Œì´ë©´ UNKNOWN
            if best_conf < 50:
                return "UNKNOWN", text
            
            return best_type, text
                
        except Exception as e:
            print(f"âš ï¸ ë¬¸ì„œ íƒ€ì… ê²€ì¶œ ì˜¤ë¥˜: {e}")
            return "UNKNOWN", ""
    
    
    def quick_ocr_for_keyword(self, pdf_path: str, page_num: int) -> Tuple[str, str]:
        """
        ì €í•´ìƒë„ OCR + Regex íŒ¨í„´ ê²€ì¶œ (1ì´ˆ)
        ìŠ¤ìº” ë¬¸ì„œì˜ íƒ€ì… ë¹ ë¥´ê²Œ íŒë³„
        """
        try:
            doc = fitz.open(pdf_path)
            page = doc[page_num]
            
            # ì €í•´ìƒë„ ì´ë¯¸ì§€ ìƒì„±
            pix = page.get_pixmap(matrix=fitz.Matrix(1.5, 1.5))
            img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
            doc.close()
            
            # ë¹ ë¥¸ OCR (ì²« 1000ì)
            text = pytesseract.image_to_string(img, config='--psm 3')[:1000]
            
            # íŒ¨í„´ ë§¤ì¹­
            text_upper = text.upper()
            best_type = None
            best_conf = 0.0
            
            for doc_type, patterns in DOCUMENT_PATTERNS.items():
                for pattern, score in patterns:
                    if re.search(pattern, text_upper):
                        if score > best_conf:
                            best_conf = score
                            best_type = doc_type
            
            if best_conf < 50:
                return "UNKNOWN", text
            
            return best_type, text
            text = pytesseract.image_to_string(img, lang='eng+kor')
            
            return text
            
        except Exception as e:
            print(f"âŒ ê³ í’ˆì§ˆ OCR ì˜¤ë¥˜: {e}")
            return ""
    def high_quality_ocr(self, pdf_path: str, page_num: int) -> str:
        """
        ê³ í’ˆì§ˆ OCR (ì „ì²´ í˜ì´ì§€) - ìŠ¤ìº” ë¬¸ì„œìš©
        """
        try:
            doc = fitz.open(pdf_path)
            page = doc[page_num]
            
            # ê³ í•´ìƒë„ ì´ë¯¸ì§€ ìƒì„± (300 DPI ì´ìƒ ê¶Œì¥, zoom=2.0)
            pix = page.get_pixmap(matrix=fitz.Matrix(2.0, 2.0))
            img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
            doc.close()
            
            # ì „ì²´ OCR ì‹¤í–‰ (í•œê¸€+ì˜ì–´)
            text = pytesseract.image_to_string(img, lang='eng+kor')
            return text
            
        except Exception as e:
            print(f"âŒ ê³ í’ˆì§ˆ OCR ì˜¤ë¥˜: {e}")
            return ""

    async def extract_with_gemini_async(self, ocr_text: str, doc_type: str, extraction_fields: List[Dict]) -> Dict:
        """
        Gemini APIë¡œ í•„ë“œ ì¶”ì¶œ (ë¹„ë™ê¸°) with êµ¬ì¡°í™”ëœ ìš”ì²­
        """
        if not self.gemini_model:
            raise Exception("Gemini APIê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # ë¬¸ì„œ íƒ€ì…ë³„ ì§€ì‹œì‚¬í•­
        doc_instruction = ""
        if doc_type == "BL":
            doc_instruction = "ì´ ë¬¸ì„œëŠ” ì„ í•˜ì¦ê¶Œ(Bill of Lading)ì…ë‹ˆë‹¤. ì„ ë°• ì •ë³´ì™€ ìš´ì†¡ ì •ë³´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”."
        elif doc_type == "INVOICE":
            doc_instruction = "ì´ ë¬¸ì„œëŠ” ìƒì—…ì†¡ì¥(Commercial Invoice)ì…ë‹ˆë‹¤. ê¸ˆì•¡ê³¼ ê±°ë˜ ì •ë³´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”."
        
        # í•„ë“œë³„ í”„ë¡¬í”„íŠ¸ ë° ì˜ˆìƒ ì‘ë‹µ êµ¬ì¡° ìƒì„±
        field_prompts = ""
        expected_fields_example = {}
        
        for field in extraction_fields:
            output_format = field.get('output_format', {})
            field_prompts += f"- {field['label']} ({field['name']}): {field['prompt']}\n"
            
            # ì˜ˆìƒ ì‘ë‹µ í˜•íƒœ ìƒì„±
            if 'currency' in output_format:
                expected_fields_example[field['name']] = {"value": 50000, "currency": "USD"}
            elif 'unit' in output_format:
                expected_fields_example[field['name']] = {"value": 1000, "unit": "MT"}
            elif output_format.get('format') == 'date':
                expected_fields_example[field['name']] = {"value": "2025-06-30", "format": "date"}
            else:
                expected_fields_example[field['name']] = {"value": "ì¶”ì¶œëœ ê°’", "format": "text"}
        
        prompt = f"""
ë‹¤ìŒ {doc_type} ë¬¸ì„œì˜ OCR í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì„¸ìš”:

{doc_instruction}

{ocr_text}

**ì¶”ì¶œí•  í•„ë“œ:**
{field_prompts}

**ì‘ë‹µ í˜•ì‹ (JSON only, ì •í™•íˆ ì•„ë˜ êµ¬ì¡°ë¥¼ ë”°ë¥´ì„¸ìš”):**
{{
  "document_type": "{doc_type}",
  "confidence": 0.95,
  "fields": {json.dumps(expected_fields_example, ensure_ascii=False, indent=2)},
  "field_confidence": {{
    {', '.join([f'"{f["name"]}": 0.95' for f in extraction_fields])}
  }},
  "notes": "ì¶”ì¶œ ê³¼ì •ì—ì„œ íŠ¹ì´ì‚¬í•­ì´ë‚˜ ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„"
}}

**ì¤‘ìš” ê·œì¹™:**
1. ëª¨ë“  ìˆ«ìì—ì„œ ì‰¼í‘œ ì œê±° (ì˜ˆ: "1,000" â†’ 1000)
2. ë‚ ì§œëŠ” ë°˜ë“œì‹œ YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ë³€í™˜
3. í†µí™”ëŠ” ISO 4217 ì½”ë“œ (USD, JPY, KRW) ì‚¬ìš©
4. ë‹¨ìœ„ëŠ” í‘œì¤€ ì•½ì–´ (MT, KG, PCS) ì‚¬ìš©
5. ê°’ì„ ì°¾ì§€ ëª»í•˜ë©´ null ë°˜í™˜
6. ìˆ˜ëŸ‰/ê¸ˆì•¡ì€ ë°˜ë“œì‹œ {{"value": ìˆ«ì, "unit": "ë‹¨ìœ„"}} ë˜ëŠ” {{"value": ìˆ«ì, "currency": "í†µí™”"}} í˜•ì‹ìœ¼ë¡œ
7. ì‘ë‹µì€ JSONë§Œ ë°˜í™˜ (ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´)
8. ì‹ ë¢°ë„(confidence)ëŠ” 0.0 ~ 1.0 ì‚¬ì´ì˜ ì†Œìˆ˜ë¡œ ê¸°ì¬í•˜ì„¸ìš”. (0.0ì€ ë°ì´í„°ê°€ ì•„ì˜ˆ ì—†ì„ ë•Œë§Œ ì‚¬ìš©)
   - ë§¤ìš° í™•ì‹¤í•¨: 0.9 ~ 1.0
   - í™•ì‹¤í•¨: 0.7 ~ 0.9
   - ë¶ˆí™•ì‹¤í•¨: 0.5 ~ 0.7
   - ì¶”ì¸¡: 0.1 ~ 0.5
"""
        
        try:
            # ë¹„ë™ê¸° í˜¸ì¶œ
            response = await self.gemini_model.generate_content_async(prompt)
            
            # í† í° ì‚¬ìš©ëŸ‰ ê³„ì‚°
            usage = response.usage_metadata
            input_tokens = usage.prompt_token_count
            output_tokens = usage.candidates_token_count
            total_tokens = usage.total_token_count
            
            # ì˜ˆìƒ ë¹„ìš© ê³„ì‚° (Gemini 1.5 Flash ê¸°ì¤€)
            input_cost = (input_tokens / 1_000_000) * 0.075 * 1400
            output_cost = (output_tokens / 1_000_000) * 0.30 * 1400
            total_cost = input_cost + output_cost
            
            token_info = {
                "input_tokens": input_tokens,
                "output_tokens": output_tokens,
                "total_tokens": total_tokens,
                "estimated_cost_krw": round(total_cost, 2)
            }
            
            raw_text = response.text.strip()
            
            # Markdown JSON ë¸”ë¡ ì œê±°
            raw_text = raw_text.replace('```json', '').replace('```', '').strip()
            if raw_text.lower().startswith('json'):
                raw_text = raw_text[4:].strip()
            
            raw_result = json.loads(raw_text)
            raw_result['token_usage'] = token_info
            
            # âœ… DataNormalizer ì ìš©
            if self.data_normalizer:
                normalized_result = self.data_normalizer.normalize_extraction_result(raw_result)
                normalized_result['token_usage'] = token_info
                return normalized_result
            else:
                return raw_result
            
        except Exception as e:
            print(f"âŒ Gemini API ë¹„ë™ê¸° í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            return {
                "document_type": doc_type,
                "confidence": 0.0,
                "fields": {},
                "field_confidence": {},
                "notes": f"API ì˜¤ë¥˜: {e}"
            }

    async def process_single_pdf_async(self, pdf_path: str, slip_id: str, extraction_mode: str = 'basic') -> Dict:
        """
        ë‹¨ì¼ PDF íŒŒì¼ ë¹„ë™ê¸° ì²˜ë¦¬
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            slip_id: ì „í‘œ ID
            extraction_mode: 'basic' ë˜ëŠ” 'detailed'
        """
        filename = os.path.basename(pdf_path).upper()
        
        # 0. íŒŒì¼ëª… ê¸°ë°˜ 1ì°¨ í•„í„°ë§
        is_target = False
        if "BILL_OF_LADING" in filename or "WAYBILL" in filename:
            is_target = True
        elif ("COMMERCIAL_INVOICE" in filename or "INVOICE" in filename) and "PACKING" not in filename:
            is_target = True
            
        if not is_target:
            return {
                "slip_id": slip_id,
                "documents": [],
                "source": "pdf_ocr"
            }

        print(f"ğŸ“„ ì²˜ë¦¬ ì‹œì‘: {os.path.basename(pdf_path)}")
        
        # ë¬¸ì„œ íƒ€ì… ê²°ì • (íŒŒì¼ëª… ê¸°ë°˜)
        doc_type = "UNKNOWN"
        if "BILL_OF_LADING" in filename or "WAYBILL" in filename:
            doc_type = "BL"
        elif "COMMERCIAL_INVOICE" in filename or "INVOICE" in filename:
            doc_type = "INVOICE"
        
        print(f"   âœ… íƒ€ì… í™•ì •: {os.path.basename(pdf_path)} -> {doc_type}")
        
        # âœ… extraction_modeì— ë”°ë¼ í•„ë“œ ì„ íƒ
        extraction_modes = self.extraction_config.get('extraction_modes', {})
        mode_config = extraction_modes.get(extraction_mode, extraction_modes.get('basic'))  # fallback to basic
        
        if mode_config and 'document_types' in mode_config:
            document_types = mode_config['document_types']
            if doc_type in document_types:
                extraction_fields = document_types[doc_type].get('fields', [])
                print(f"   ğŸ“‹ {extraction_mode} ëª¨ë“œ - {doc_type} í•„ë“œ: {len(extraction_fields)}ê°œ")
            else:
                print(f"   âš ï¸ {doc_type} ì„¤ì • ì—†ìŒ, ìŠ¤í‚µ")
                return {
                    "slip_id": slip_id,
                    "documents": [],
                    "source": "pdf_ocr"
                }
        else:
            print(f"   âš ï¸ extraction_mode '{extraction_mode}' ì„¤ì • ì—†ìŒ")
            return {
                "slip_id": slip_id,
                "documents": [],
                "source": "pdf_ocr"
            }
        
        documents = []
        
        try:
            full_text = ""
            doc = fitz.open(pdf_path)
            num_pages = len(doc)
            pages_to_read = min(num_pages, 3)
            
            for i in range(pages_to_read):
                page = doc[i]
                text = page.get_text()
                if len(text.strip()) < OCR_THRESHOLD:
                    text = self.high_quality_ocr(pdf_path, i)
                full_text += f"\n--- Page {i+1} ---\n{text}"
            
            doc.close()
            
            # 3. Gemini API ë¹„ë™ê¸° í˜¸ì¶œ
            print(f"   ğŸ¤– API ìš”ì²­: {os.path.basename(pdf_path)}")
            extraction_result = await self.extract_with_gemini_async(full_text, doc_type, extraction_fields)
            
            extraction_result['page'] = 1
            extraction_result['type'] = doc_type
            extraction_result['file_name'] = os.path.basename(pdf_path)
            
            documents.append(extraction_result)
            print(f"   âœ¨ ì™„ë£Œ: {os.path.basename(pdf_path)}")
            
            return {
                "slip_id": slip_id,
                "documents": documents,
                "source": "pdf_ocr"
            }
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ({os.path.basename(pdf_path)}): {e}")
            return {
                "slip_id": slip_id,
                "documents": [],
                "error": str(e)
            }


    async def process_project_pdfs_async(self, project_id: str, split_dir: str, extraction_mode: str = 'basic', target_ids: List[str] = None) -> List[Dict]:
        """
        í”„ë¡œì íŠ¸ ì „ì²´ PDF ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬
        OPTIMIZED: Only scans extraction_targets/ subfolder (BL & Invoice)
        Falls back to root folder for backward compatibility
        
        Args:
            project_id: í”„ë¡œì íŠ¸ ID
            split_dir: split_documents í´ë” ê²½ë¡œ
            extraction_mode: 'basic' ë˜ëŠ” 'detailed'
            target_ids: ì²˜ë¦¬í•  ì „í‘œ ID ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ì „ì²´ ì²˜ë¦¬)
        """
        print(f"ğŸš€ í”„ë¡œì íŠ¸ {project_id} ë¹„ë™ê¸° ì²˜ë¦¬ ì‹œì‘ (ëª¨ë“œ: {extraction_mode}, ëŒ€ìƒ: {'ì „ì²´' if not target_ids else len(target_ids)})")
        
        if not os.path.exists(split_dir):
            print(f"âŒ í´ë” ì—†ìŒ: {split_dir}")
            return []
        
        # ëª¨ë“  PDF íŒŒì¼ ìˆ˜ì§‘ (extraction_targetsë§Œ ìŠ¤ìº”í•˜ì—¬ ì†ë„ í–¥ìƒ)
        tasks = []
        semaphore = asyncio.Semaphore(3)  # ë™ì‹œì— 3ê°œê¹Œì§€ë§Œ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ ë³´í˜¸)
        
        async def sem_task(pdf_path, slip_id):
            async with semaphore:
                return await self.process_single_pdf_async(pdf_path, slip_id, extraction_mode)

        for slip_folder in os.listdir(split_dir):
            slip_path = os.path.join(split_dir, slip_folder)
            if not os.path.isdir(slip_path):
                continue
                
            slip_id = slip_folder
            
            # í•„í„°ë§: target_idsê°€ ìˆê³ , í˜„ì¬ slip_idê°€ ê·¸ ì•ˆì— ì—†ìœ¼ë©´ ìŠ¤í‚µ
            if target_ids is not None and slip_id not in target_ids:
                continue
            
            # âœ… OPTIMIZED: Check extraction_targets/ subfolder first
            extraction_targets_path = os.path.join(slip_path, 'extraction_targets')
            
            if os.path.exists(extraction_targets_path) and os.path.isdir(extraction_targets_path):
                # New structure: only scan extraction_targets/
                pdf_files = [f for f in os.listdir(extraction_targets_path) if f.lower().endswith('.pdf')]
                print(f"  âœ… {slip_id}: {len(pdf_files)} extraction target(s) found")
                
                for pdf_file in pdf_files:
                    pdf_path = os.path.join(extraction_targets_path, pdf_file)
                    tasks.append(sem_task(pdf_path, slip_id))
            else:
                # Fallback: Old structure - scan root folder
                # (This ensures backward compatibility with existing projects)
                pdf_files = [f for f in os.listdir(slip_path) if f.lower().endswith('.pdf')]
                print(f"  âš ï¸  {slip_id}: Using old structure, {len(pdf_files)} file(s) found")
                
                for pdf_file in pdf_files:
                    pdf_path = os.path.join(slip_path, pdf_file)
                    tasks.append(sem_task(pdf_path, slip_id))
        
        print(f"ğŸ“Š ì´ {len(tasks)}ê°œ íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘... (extraction_targetsë§Œ ìŠ¤ìº”)")
        
        # ë³‘ë ¬ ì‹¤í–‰
        try:
            results = await asyncio.gather(*tasks)
        except Exception as e:
            print(f"[CRITICAL ERROR] asyncio.gather failed: {e}")
            import traceback
            traceback.print_exc()
            with open("crash_log_engine.txt", "a") as f:
                f.write(f"[{datetime.now()}] Crash in smart_extraction_engine gather: {e}\n")
                f.write(traceback.format_exc())
            raise e
        
        # ê²°ê³¼ ì§‘ê³„ (ì „í‘œë³„ë¡œ ë¬¶ê¸°)
        slip_results_map = {}
        
        for res in results:
            slip_id = res.get('slip_id')
            if not slip_id: continue
            
            if slip_id not in slip_results_map:
                slip_results_map[slip_id] = {
                    "slip_id": slip_id,
                    "documents": [],
                    "source": "pdf_ocr"
                }
            
            if 'documents' in res:
                slip_results_map[slip_id]['documents'].extend(res['documents'])
        
        final_results = list(slip_results_map.values())
        print(f"âœ… ì´ {len(final_results)}ê°œ ì „í‘œ ì²˜ë¦¬ ì™„ë£Œ")
        return final_results

    # ë™ê¸° ë©”ì„œë“œ ìœ ì§€ (í•˜ìœ„ í˜¸í™˜ì„±)
    def process_single_pdf(self, pdf_path: str, slip_id: str, extraction_mode: str = 'basic', ocr_json_dir: str = None) -> Dict:
        return asyncio.run(self.process_single_pdf_async(pdf_path, slip_id, extraction_mode))



if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    engine = SmartExtractionEngine()
    print("SmartExtractionEngine ì´ˆê¸°í™” ì™„ë£Œ")

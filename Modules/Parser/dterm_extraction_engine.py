# -*- coding: utf-8 -*-
"""
D-Term Extraction Engine - Hybrid OCR + Gemini API
Dì¡°ê±´(ë„ì°© ê¸°ì¤€) ì¦ë¹™ ë¬¸ì„œì—ì„œ 'ë„ì°©ì¼(Arrival Date)'ê³¼ 'ë¬¸ì„œ ìœ í˜•'ì„ ì¶”ì¶œí•˜ëŠ” ì „ìš© ì—”ì§„
ê¸°ì¡´ SmartExtractionEngineì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë˜, Dì¡°ê±´ ìš”êµ¬ì‚¬í•­ì— ë§ì¶° ë…ë¦½ì ìœ¼ë¡œ ë™ì‘í•¨.
"""

import fitz  # PyMuPDF
import pytesseract
from PIL import Image
import io
import os
import asyncio
import json
import re
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import google.generativeai as genai

# Tesseract ê²½ë¡œ ì„¤ì • (í™˜ê²½ì— ë”°ë¼ ìˆ˜ì • ê°€ëŠ¥)
TESSERACT_PATH = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
try:
    pytesseract.pytesseract.tesseract_cmd = TESSERACT_PATH
except:
    print("âš ï¸ D-Term Engine: Tesseract ê²½ë¡œ ì„¤ì • ì˜¤ë¥˜")

# OCR ì„ê³„ê°’
OCR_THRESHOLD = 50  # í…ìŠ¤íŠ¸ê°€ ì´ ê°’ë³´ë‹¤ ì ìœ¼ë©´ ìŠ¤ìº” PDFë¡œ ê°„ì£¼

class DtermExtractionEngine:
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.gemini_model = None
        self.semaphore = asyncio.Semaphore(5)  # ë³‘ë ¬ ì²˜ë¦¬ ì œí•œ
        self._load_configs()
    
    def _load_configs(self):
        """ì„¤ì • ë¡œë“œ ë° Gemini ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
            import sys
            project_root = Path(__file__).parent.parent.parent
            if str(project_root) not in sys.path:
                sys.path.insert(0, str(project_root))
            
            # Gemini API í‚¤ ë¡œë“œ
            from Config.api_config import GEMINI_API_KEY
            genai.configure(api_key=GEMINI_API_KEY)
            
            # ìµœì‹  ì‹œìŠ¤í…œ ì§€ì‹œì‚¬í•­
            SYSTEM_INSTRUCTION = """
            You are an expert in Logistics and Trade Finance documents.
            Your specialization is identifying "Proof of Arrival" or "Proof of Delivery" for D-Term (DAP, DDP, DAT) transactions.
            Your goal is to find the EXACT date when the cargo arrived at the destination or was received by the consignee.
            Output must be in pure JSON format.
            """
            
            try:
                # SmartExtractionEngineê³¼ ë™ì¼í•˜ê²Œ Gemini 2.0 ëª¨ë¸ ì‚¬ìš©
                self.gemini_model = genai.GenerativeModel(
                    model_name='models/gemini-2.0-flash',
                    system_instruction=SYSTEM_INSTRUCTION
                )
            except Exception as e:
                print(f"âŒ Model initialization error: {e}")
                raise
            
            print("âœ… D-Term Engine: Gemini API initialized")
            
        except Exception as e:
            print(f"âŒ D-Term Engine initialization failed: {e}")
            raise

    def high_quality_ocr(self, pdf_path: str, page_num: int) -> str:
        """ê³ í’ˆì§ˆ OCR (ì „ì²´ í˜ì´ì§€) - ìŠ¤ìº” ë¬¸ì„œìš©"""
        try:
            doc = fitz.open(pdf_path)
            page = doc[page_num]
            pix = page.get_pixmap(matrix=fitz.Matrix(3.0, 3.0))
            img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
            doc.close()
            text = pytesseract.image_to_string(img, lang='eng+kor')
            return text
        except Exception as e:
            print(f"âŒ OCR Error: {e}")
            return ""

    async def extract_with_gemini_vision_async(self, pdf_path: str, filename: str, context: Dict = None) -> Dict:
        """Gemini Vision API (ì´ë¯¸ì§€ ë¶„ì„) - í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ Fallback"""
        print(f"ğŸ‘ï¸ Vision Fallback Triggered for {filename}")
        try:
            # 1. PDF ì²« í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
            doc = fitz.open(pdf_path)
            if len(doc) < 1: return {}
            
            # ì¤‘ìš”: ë¬¼ë¥˜ ë¬¸ì„œëŠ” 1~2í˜ì´ì§€ì— í•µì‹¬ ì •ë³´ê°€ ìˆìŒ (íŠ¹íˆ 2í˜ì´ì§€ ìŠ¤ì¼€ì¤„)
            images = []
            pages_to_check = min(len(doc), 2)
            
            for i in range(pages_to_check):
                page = doc[i]
                pix = page.get_pixmap(matrix=fitz.Matrix(2.0, 2.0)) # ê³ í•´ìƒë„
                img_data = pix.tobytes("png")
                img = Image.open(io.BytesIO(img_data))
                images.append(img)
            
            doc.close()
            
            # Context Prep (Directive A: Flexible Matching)
            context_str = ""
            if context:
                context_str = f"""
                **Context Validation Keys:**
                - Primary: TC No ({context.get('tc', 'N/A')}), SO No ({context.get('so', 'N/A')}), Invoice ({context.get('invoice', 'N/A')})
                - Secondary (Use if Primary missing): 
                  - Registrant Name: {context.get('registrant', 'N/A')}
                  - Sales Person: {context.get('sales_person', 'N/A')} 
                  - Customer: {context.get('customer_desc', 'N/A')}
                """

            prompt = [
                f"""
                Analyze these document images (Logistics Documents).
                Filename: {filename}
                
                {context_str}
                
                **Objective**: Identify the **FINAL ARRIVAL DATE** of the cargo at the Ultimate Destination.
                
                **Rule 1: Flexible Matching (Directive A)**
                - If TC/SO/Invoice are not found, check the "Secondary" keys (Registrant, Customer). 
                - If the filename ({filename}) contains the Slip ID or partial TC, consider it a MATCH.
                
                **Rule 2: Final Port Rule (Directive B)**
                - **Crucial**: In a Vessel Schedule or Tracking Report, look for the **List of Ports**.
                - Select the date for the **LAST Port of Discharge** (Ultimate POD) in the sequence.
                - Ignore "Pol (Port of Loading)" or intermediate transshipment ports. 
                - If multiple "Discharging" dates exist, pick the LATEST one.
                
                **Rule 3: Robust Parsing (Directive C)**
                - Extract ONLY the date part (YYYY-MM-DD).
                - STRIP extraneous text like "1000LT", "BERTHED", "Completed", "ATA".
                - Example: "2025/11/22 0642LT" -> "2025-11-22"
                - DO NOT return "null" if a valid date exists in a messy format.
                
                **Rule 4: Reasoning (Directive D - Korean Output)**
                - You MUST list ALL ports found in the schedule and explain selection logic in **KOREAN**.
                - Format: "ë°œê²¬ëœ í•­êµ¬: [Port List]. [Reason for Selection]ì— ë”°ë¼ [Date]ë¥¼ ì„ íƒí•¨."
                - Example: "ìŠ¤ì¼€ì¤„ìƒ ë¶€ì‚°, ì‹±ê°€í¬ë¥´, ë¡œí…Œë¥´ë‹´ ë°œê²¬. ìµœì¢… ëª©ì ì§€ì¸ ë¡œí…Œë¥´ë‹´ì˜ í•˜ì—­ì¼(12/02)ì„ ì„ íƒí•¨."
                
                **Output JSON**:
                {{
                    "verification_status": "Perfect Match" | "Match - Date Only" | "Mismatch" | "Unidentified",
                    "matched_identifiers": ["List found keys"],
                    "extracted_arrival_date": "YYYY-MM-DD",
                    "date_confidence": 0.0 to 1.0,
                    "doc_category": "Document Type",
                    "reasoning": "Reasoning in Korean (Simple & Clear)."
                }}
                """
            ]
            
            response = await self.gemini_model.generate_content_async(
                prompt + images, 
                generation_config={"response_mime_type": "application/json"}
            )
            
            result = json.loads(response.text)
            if isinstance(result, list): result = result[0]
            
            return result
            
        except Exception as e:
            print(f"âŒ Vision API Error: {e}")
            return {
                "verification_status": "Error",
                "reasoning": f"Vision Error: {str(e)}"
            }

    async def extract_with_gemini_async(self, ocr_text: str, filename: str, context: Dict = None) -> Dict:
        """Gemini APIë¡œ ë„ì°©ì¼ ë° ë¬¸ì„œ ìœ í˜• ì¶”ì¶œ (Context-Aware)"""
        if not self.gemini_model:
            raise Exception("Gemini API not initialized")
            
        # Context Injection (Directive A)
        context_str = ""
        if context:
            context_str = f"""
            **Context Validation Keys:**
            - Primary: TC No ({context.get('tc', 'N/A')}), SO No ({context.get('so', 'N/A')}), Invoice ({context.get('invoice', 'N/A')})
            - Secondary (Backup): Registrant ({context.get('registrant', 'N/A')}), Customer ({context.get('customer_desc', 'N/A')})
            """

        prompt = f"""
        Analyze the following text extracted from a logistics document ("{filename}").
        
        {context_str}
        
        **Objective**: Identify the **FINAL ARRIVAL DATE** of the cargo at the Ultimate Destination.
        
        **Advanced Parsing Rules (Directives)**:
        
        1.  **Flexible Matching (Directive A)**:
            - If Primary Keys (TC/SO) are missing, validate using Secondary Keys or the Filename itself.
            - If matching is ambiguous but the document clearly shows arrival info, mark as "Match - Date Only".
            
        2.  **Final Port Rule (Directive B)**:
            - **CRITICAL**: For Sea Freight, find the **Vessel Schedule**.
            - Identify the sequence of ports. The Arrival Date is the 'Discharged' or 'ATA' at the **LAST Port**.
            - IGNORE dates for 'Port of Loading' or 'Transshipment'.
            - Reference: "Commenced Discharging" > "ATA".
            
        3.  **Robust Parsing (Directive C)**:
            - Output format: YYYY-MM-DD
            - Clean up noise: Remove "1000LT", "BERTHED", time, or codes from the date string.
            - If the text says "22-Nov-2025", convert to "2025-11-22".
            
        4.  **Reasoning (Directive D - Korean Output)**:
            - Write the reasoning in **KOREAN**.
            - Be concise and clear. List found ports/dates and why the final date was chosen.
            - Example: "ë¬¸ì„œì—ì„œ ë¶€ì‚°, LA, ë‰´ìš• í•­êµ¬ ë°œê²¬. ìµœì¢… ë„ì°©ì§€ì¸ ë‰´ìš•ì˜ ATA(12/25)ë¥¼ ì¶”ì¶œí•¨."

        **JSON Output Format**:
        {{
            "verification_status": "Perfect Match" | "Match - Date Only" | "Mismatch" | "Unidentified",
            "matched_identifiers": ["List found keys"],
            "extracted_arrival_date": "YYYY-MM-DD",
            "date_confidence": 0.0 to 1.0,
            "doc_category": "Category Name",
            "evidence_text": "Quote the text that proves the date.",
            "reasoning": "Reasoning in Korean (Simple & Clear)."
        }}
        
        **Input Text:**
        {ocr_text[:14000]}
        """
        
        try:
            response = await self.gemini_model.generate_content_async(
                prompt,
                generation_config={"response_mime_type": "application/json"}
            )
            
            result = json.loads(response.text)
            
            if isinstance(result, list):
                result = result[0] if result else {}
                
            return result
            
        except Exception as e:
            print(f"âŒ API Error: {e}")
            return {
                "verification_status": "Error",
                "extracted_arrival_date": None,
                "reasoning": str(e)
            }

    async def process_single_pdf_async(self, pdf_path: str, slip_id: str, context: Dict = None) -> Dict:
        """ë‹¨ì¼ PDF ì²˜ë¦¬ (Text -> Low Confidence -> Vision Fallback)"""
        filename = os.path.basename(pdf_path)
        print(f"ğŸ“„ D-Term Processing: {filename}")
        
        try:
            # 1. ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (OCR)
            doc = fitz.open(pdf_path)
            pages_to_read = min(len(doc), 3) # ì²« 3í˜ì´ì§€ ë¶„ì„ (ìŠ¤ì¼€ì¤„ ë“± í™•ì¸)
            full_text = ""
            
            for i in range(pages_to_read):
                page = doc[i]
                text = page.get_text()
                if len(text.strip()) < OCR_THRESHOLD:
                    text = self.high_quality_ocr(pdf_path, i)
                full_text += f"\n--- Page {i+1} ---\n{text}"
            
            doc.close()
            
            # 2. Text-based Gemini Analysis
            extraction = await self.extract_with_gemini_async(full_text, filename, context)
            
            # 3. Vision Fallback Check
            # ì¡°ê±´: ë‚ ì§œê°€ ì—†ê±°ë‚˜(Unidentified), ì‹ ë¢°ë„ê°€ ë‚®ê±°ë‚˜(0.8 ë¯¸ë§Œ), ë¬¸ì„œ ìœ í˜•ì´ Unknownì¸ ê²½ìš°
            security_check = extraction.get("verification_status", "Unidentified")
            confidence = extraction.get("date_confidence", 0.0)
            
            if security_check == "Unidentified" or confidence < 0.8:
                print(f"âš ï¸ Low confidence ({confidence}) for {filename}. Attempting Vision Fallback...")
                vision_result = await self.extract_with_gemini_vision_async(pdf_path, filename, context)
                
                # Vision ê²°ê³¼ê°€ ë” ì¢‹ìœ¼ë©´(ë‚ ì§œê°€ ìˆê±°ë‚˜ ì‹ ë¢°ë„ê°€ ë†’ìœ¼ë©´) êµì²´
                v_date = vision_result.get("extracted_arrival_date")
                v_conf = vision_result.get("date_confidence", 0.0)
                
                if v_date and v_conf >= confidence:
                    print(f"âœ… Vision Result Accepted for {filename} (Date: {v_date}, Conf: {v_conf})")
                    extraction = vision_result
                    extraction['method'] = 'vision'
                else:
                    print(f"â„¹ï¸ Vision result not better. Keeping text result.")
            
            # 4. ê²°ê³¼ í¬ë§·íŒ…
            return {
                "slip_id": slip_id,
                "file_name": filename,
                "document_type": extraction.get("doc_category", "Unknown"),
                "arrival_date": extraction.get("extracted_arrival_date"),
                "date_confidence": extraction.get("date_confidence", 0.0),
                "reasoning": extraction.get("reasoning", ""),
                "evidence_text": extraction.get("evidence_text", ""),
                "verification_status": extraction.get("verification_status", "Unidentified"),
                "matched_identifiers": extraction.get("matched_identifiers", []),
                "method": extraction.get("method", "text")
            }
            
        except Exception as e:
            print(f"âŒ File Processing Error: {e}")
            return {
                "slip_id": slip_id, 
                "file_name": filename, 
                "error": str(e)
            }

    async def process_project_dterm_async(self, project_id: str, split_dir: str, target_ids: List[str] = None, progress_callback=None, context_map: Dict = None) -> List[Dict]:
        """í”„ë¡œì íŠ¸ ì „ì²´ Dì¡°ê±´ ì¦ë¹™ ì²˜ë¦¬"""
        # split_dir êµ¬ì¡°: slip_id í´ë” í•˜ìœ„ íŒŒì¼ë“¤
        
        tasks = []
        files_to_process = []
        
        # 1. íŒŒì¼ ìˆ˜ì§‘
        if os.path.exists(split_dir):
            for item in os.listdir(split_dir):
                item_path = os.path.join(split_dir, item)
                
                # í´ë”ì¸ ê²½ìš° (slip_id)
                if os.path.isdir(item_path):
                    slip_id = item
                    if target_ids and slip_id not in target_ids:
                        continue
                        
                    for f in os.listdir(item_path):
                        if f.lower().endswith(('.pdf', '.png', '.jpg', '.jpeg')):
                            files_to_process.append((os.path.join(item_path, f), slip_id))
                            
                # íŒŒì¼ì¸ ê²½ìš° (íŒŒì¼ëª… ë§¤ì¹­)
                elif os.path.isfile(item_path) and item.lower().endswith(('.pdf', '.png', '.jpg', '.jpeg')):
                    # íŒŒì¼ëª…ì—ì„œ slip_id ìœ ì¶” ì‹œë„
                    # ë¡œì§ ê°œì„ : ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœíˆ íŒŒì¼ëª… ë§¤ì¹­ë§Œ ì‹œë„í•˜ì§€ë§Œ, 
                    # Step 3 Loopì—ì„œ context mapì„ ìˆœíšŒí•˜ë©° íŒŒì¼ì„ ì°¾ëŠ” ë°©ì‹ì´ ë” ì •í™•í•  ìˆ˜ ìˆìŒ.
                    # í˜„ì¬ êµ¬ì¡° ìœ ì§€í•˜ë˜ context ì „ë‹¬.
                    match = re.match(r'^(\d{8,})_', item)
                    slip_id = match.group(1) if match else "Unknown"
                    
                    # context_mapì— slip_idê°€ ìˆë‹¤ë©´ ìœ íš¨í•œ ê²ƒìœ¼ë¡œ ê°„ì£¼
                    if slip_id == "Unknown" and context_map:
                         # íŒŒì¼ëª… ì „ì²´ì—ì„œ SID ê²€ìƒ‰ (ë³´ì™„)
                         for known_sid in context_map.keys():
                             if known_sid in item:
                                 slip_id = known_sid
                                 break
                    
                    if target_ids and slip_id not in target_ids:
                        continue
                        
                    files_to_process.append((item_path, slip_id))

        total_files = len(files_to_process)
        print(f"ğŸš€ D-Term Engine: Found {total_files} files to process with Context-Aware Logic")
        
        for idx, (fpath, slip_id) in enumerate(files_to_process):
            if progress_callback:
                progress_callback(idx, total_files, slip_id, f"Queued {os.path.basename(fpath)}")
            
            # Context Lookup
            ctx = context_map.get(slip_id) if context_map else None
            tasks.append(self.process_single_pdf_async(fpath, slip_id, context=ctx))
            
        # 2. ë³‘ë ¬ ì‹¤í–‰
        results = []
        chunk_size = 5 # Semaphore ì œí•œê³¼ ë³„ë„ë¡œ ì²­í¬ ì²˜ë¦¬
        for i in range(0, len(tasks), chunk_size):
            chunk = tasks[i:i+chunk_size]
            chunk_results = await asyncio.gather(*chunk)
            results.extend(chunk_results)
            
            # Progress Update
            if progress_callback:
                progress_callback(min(i+chunk_size, total_files), total_files, "Batch", "Processing...")
                
        return results
